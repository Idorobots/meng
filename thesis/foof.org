# ###############################################################################
#+TITLE:
#+AUTHOR: Kajetan Rzepecki
#+DATE: 2015
#+LANGUAGE: pl
#
#+STARTUP: content
#+EXPORT_SELECT_TAGS: export
#+LaTeX_CLASS: aghdpl
#+LaTeX_CLASS_OPTIONS: [a4paper, 12pt]
#+LaTeX_HEADER: \usepackage[polish]{babel}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{multicol}
#+LATEX_HEADER: \usepackage[nottoc, notlof, notlot]{tocbibind}
#+OPTIONS: tags:nil, todo:nil, toc:nil
# ###################

# Helpers & Stuff
#+begin_src emacs-lisp :exports none
  (setq org-latex-minted-options
        '(("frame" "leftline") ("linenos" "true") ("mathescape" "true")))

  (setq org-export-latex-title-command "")
  (add-to-list 'org-latex-classes
               '("aghdpl"
                 "\\documentclass{aghdpl}"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")
                 ))

  (setq org-latex-classes (cdr org-latex-classes))
#+end_src

# AGH setup:
#+LATEX_HEADER: \shortauthor{K. Rzepecki}
#+LATEX_HEADER: \degreeprogramme{Informatyka}

#+LATEX_HEADER: \thesistype{Praca dyplomowa magisterska}

#+LATEX_HEADER: \titlePL{Projekt języka programowania wspierającego przetwarzanie rozproszone na platformach heterogenicznych.}
#+LATEX_HEADER: \titleEN{Design of a programming language with support for distributed computing on heterogenous platforms.}

#+LATEX_HEADER: \shorttitlePL{Projekt języka programowania wspierającego przetwarzanie rozproszone \dots}
#+LATEX_HEADER: \shorttitleEN{Design of a programming language with support for distributed computing \dots}

#+LATEX_HEADER: \supervisor{dr inż. Piotr Matyasik}

#+LATEX_HEADER: \department{Katedra Informatyki Stosowanej}

#+LATEX_HEADER: \faculty{Wydział Elektrotechniki, Automatyki,\protect\\[-1mm] Informatyki i Inżynierii Biomedycznej}

#+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję opiekunowi pracy za wsparcie merytoryczne oraz dobre rady edytorskie pomocne w tworzeniu pracy.}
# #+LATEX_HEADER: \acknowledgements{Serdecznie dziękuję Lucynie oraz siostrze Alicji za cierpliwość i wsparcie podczas tworzenia pracy dyplomowej.}

# Font stuff:
#+LATEX_HEADER: \setmainfont{Times New Roman}
#+LATEX_HEADER: \setmonofont{Consolas}

# Title pages & table of contents:
#+begin_latex
\titlepages
\tableofcontents
#+end_latex

# List of Listings specific:
#+begin_latex
\newcommand{\listlistingname}{\bfseries\Large{Spis listingów}}
\newlistof[chapter]{mylisting}{mlol}{\listlistingname}
\newcommand{\mylisting}[1]{%
  \refstepcounter{mylisting}%
  #1%
  \addcontentsline{mlol}{figure}
    {\protect\numberline{\thechapter.\thelisting}#1}\par%
}
\renewcommand{\cftbeforemloltitleskip}{20mm}
\renewcommand{\cftaftermloltitleskip}{5mm}
#+end_latex

* Wstęp
#+latex: \label{sec:intro}

Tematem pracy jest projekt i implementacja języka programowania wspierającego /przetwarzanie współbieżne/ i umożliwiającego tworzenie /systemów rozproszonych/ działających na /platformach heterogenicznych/.

Przetwarzanie współbieżne polega na podziale obliczeń na wiele procesów działających jednocześnie i konkurujących ze sobą o dostęp do ograniczonej ilości zasobów [[cite:McKenney2015]]. Procesy te mogą zostać rozproszone na wiele fizycznych maszyn, zachowując jednocześnie komunikację pomiędzy nimi, tworząc tym samym jeden koherentny system rozproszony [[cite:Tanenbaum2006]].

Projektowany język programowania powinien więc udostępniać przejrzystą i ogólną notację umożliwiającą definiowanie komunikujących się procesów, jednocześnie pozostając językiem ogólnego przeznaczenia. Dodatkowym wymogiem jest prostota przy zachowaniu ekspresywności - język ten powinien być zbudowany w oparciu o niewielką liczbę ortogonalnych, dobrze współgrających ze sobą mechanizmów, które pozwalają na implementację szerokiej gamy funkcjonalności [[cite:Backus1978]].

#+begin_center
#+label: fig:lang-parts
#+caption: Schemat interakcji poszczególnych elementów języka.
#+attr_latex: :width 0.8\textwidth :placement [H]
[[file:./img/langparts.pdf]]
#+end_center

W tym celu wymagane jest stworzenie kompilatora, czyli programu transformującego kod źródłowy języka programowania na format możliwy do uruchomienia w pewnym środowisku uruchomieniowym (ang. /runtime system/). Na środowisko takie zazwyczaj składa się zestaw podstawowych procedur wspólnych i niezbędnych do działania każdego programu. Schemat interakcji poszczególnych elementów projektu zaprezentowano na schemacie [[fig:lang-parts]].

Ostatnim wymogiem postawionym przed projektowanym językiem, jest wyjście naprzeciw licznym problemom występującym w systemach rozproszonych, w szczególności problemowi /heterogeniczności/, co umotywowano w sekcji [[ref:sec:thesis-motivation]].

** Motywacja pracy
#+LaTeX: \label{sec:thesis-motivation}

Tworzenie systemów rozproszonych jest zadaniem bardzo trudnym i wymaga wykorzystania specjalnie do tego przeznaczonych narzędzi - języków programowania, systemów bazodanowych i infrastruktury sieciowej. Na przestrzeni lat zidentyfikowano wiele kluczowych problemów manifestujących się we wszystkich systemach rozproszonych niezależnie od ich przeznaczenia. Tanenbaum oraz Van Steen w [[cite:Tanenbaum2006]] wymieniają następujące problemy:

- *dostępność* - systemy rozproszone działają zwykle na wielu odrębnych maszynach, istotnym jest więc zachowanie dostępu do wspólnych zasobów z każdej części systemu,

- *przezroczystość dystrybucji* - istotnym jest również ukrycie fizycznego rozproszenia procesów i zasobów, dzięki czemu system rozproszony z zewnątrz stanowi jedną, koherentną całość,

- *otwartość* - polega na standaryzacji komunikacji pomiędzy poszczególnymi częściami systemu, dzięki czemu możliwe jest dodawanie nowych elementów bez ingerencji w pozostałe,

- *skalowalność* - systemy rozproszone powinny umożliwiać płynną zmianę ilości zasobów, być dostępne dla użytkowników z wielu lokacji geograficznych oraz umożliwiać łatwe zarządzanie niezależnie od ich rozmiaru.

Warto zauważyć, iż /skalowalność/ jest przywoływana w folklorze programistycznym nieproporcjonalnie często, natomiast, istnieje wiele równie trudnych problemów, którym przeznacza się znacznie mniej uwagi, takich jak:

- *bezpieczeństwo systemu* - polega na kontroli dostępu do zasobów; w zależności od przeznaczenia systemu rozproszonego, jest najważniejszym aspektem jego budowy,

- *odporność na błędy* - polega na reagowaniu na zmiany (w szczególności wystąpienie błędów) zachodzące w systemie i podejmowaniu odpowiednich akcji w razie ich wystąpienia,

- *heterogeniczność* - polega na zróżnicowaniu platform sprzętowych wchodzących w skład fizycznej części systemu rozproszonego, a także poszczególnych logicznych części systemu.

Heterogeniczność jest problemem szczególnie trudnym, który powoli nabiera znaczenia wraz z pojawieniem się inicjatyw takich jak *Internet Rzeczy* (ang. /Internet of Things/) [[cite:Holler2014]], gdzie systemy rozproszone zbudowane są z dużej ilości bardzo zróżnicowanych maszyn. Maszyny te cechują się różną architekturą sprzętową, ilością zasobów, a także przeznaczeniem i funkcjonalnościami, które realizują i umożliwiają.

Na schemacie [[fig:hetero-iot]] przedstawiony został przykład heterogeniczności platformy sprzętowej w kontekście Internetu Rzeczy. Klient, korzystając z centralnego komputera, uzyskuje dostęp do danych sensorycznych pochodzących z szerokiej gamy różnych czujników i bazując na ich wartości jest w stanie zmieniać zachowanie równie zróżnicowanych efektorów. Całość odbywa się za pośrednictwem dedykowanych sterowników, ułatwiających skalowanie systemu.

#+begin_center
#+label: fig:hetero-iot
#+caption: Przykład systemu opartego o heterogeniczną platformę sprzętową.
#+attr_latex: :width 0.7\textwidth :placement [H]
[[file:./img/heteroiotexample.pdf]]
#+end_center

Każdy element takiego systemu, oznaczony na schemacie różnym kształtem oraz kolorem, reprezentuje maszynę udostępniającą różne zasoby i posiadającą różną fizyczną konstrukcję. Poszczególne elementy często działają w niekompatybilny sposób, w związku z czym wymagane jest wykorzystanie dedykowanych pośredników, których jedynym zadaniem jest /homogenizacja/ systemu.

Problem heterogeniczności dotyka również systemów rozproszonych, które działają na platformach homogenicznych, gdzie fizyczne maszyny są do siebie bardzo zbliżone, a często są komputerami ogólnego przeznaczenia. Przykład takiego systemu, zbudowanego w oparciu o zdobywającą popularność architekturę mikroserwisową [[cite:Richards2015]], został zawarty na schemacie [[fig:hetero-service]].

Użytkownik systemu łączy się z głównym serwisem, który następnie komunikuje się z innymi serwisami, realizującymi wymagane przezeń zadania. W celu poprawienia /odporności na błędy/ takiego systemu, w strategicznych miejscach umieszczono serwery zarządzające ruchem (ang. /load-balancer/), których zadaniem, analogicznie do przykładu ze schematu [[fig:hetero-iot]], jest /homogenizacja/ systemu.

#+begin_center
#+label: fig:hetero-service
#+caption: Przykład systemu heterogenicznego niezależnie od platformy sprzętowej.
#+attr_latex: :width 0.7\textwidth :placement [H]
[[file:./img/heteroserviceexample.pdf]]
#+end_center

W pierszym przypadku heterogeniczność wynika ze zróżnicowania maszyn należących do platformy sprzętowej, natomiast w drugim wynika ona z istnienia mikroserwisów, które realizują pojedyncze, konretnie sprecyzowane funkcjonalności. W obu przypadkach, heterogeniczność systemu prowadzi do powstania innych problemów, takich jak skalowalność i odporność na błędy, oraz konieczności wykorzystania dodatkowych elementów mających im zaradzić.

Często, sytuacja ta wynika z nieadekwatności narzędzi (w szczególności języków programowania) wykorzystanych do tworzenia systemu. Popularne języki programowania dążą do osiągnięcia *niezalożności od platformy* (ang. /platform independence/) stosując maszyny wirtualne i inne techniki mające na celu homogenizację platformy sprzętowej, kiedy w rzeczywistości osiągają *ignorancję platformy* nie umożliwiając refleksji na jej temat.

Jako alternatywę dla osiągnięcia niezależności od platformy, niniejsza praca wprowadza termin *świadomości platformy* (ang. /platform awareness/), czyli dążenia do udostępnienia wiedzy o strukturze budowanego systemu rozproszonego oraz platformy sprzętowej, na której działa, i umożliwienia refleksji na jej podstawie. Zaprezentowany w dalszej części pracy język programowania, roboczo zwany =FOOF= [fn:: Nazwa pochodzi od difluorku ditlenu, niezwykle reaktywnego, dysruptywnego i niebezpiecznego związku chemicznego, który nie ma żadnego zastosowania.], ma być uosobieniem ideologii świadomości platformy.

#+LaTeX: \vfill

#+LaTeX: \pagebreak
** Zawartość pracy
Praca została podzielona na cztery rozdziały tematyczne, wstęp oraz podsumowanie. Dodatkowo, do pracy dołączono szereg dodatków.

Rozdział [[ref:sec:intro]] zawiera motywację, opis zawartości i definicję problemów rozpatrywanych w dalszej części pracy.

Rozdział [[ref:sec:lang-description]] zawiera szczegółowy opis projektu języka programowania =FOOF= począwszy od podstawowych typów danych w nim dostępnych, przez bardziej skomplikowane struktury danych, jak funkcje i kontynuacje, kończąc na zaawansowanych mechanizmach służących realizacji zadań postawionych przed językiem.

Rozdział [[ref:sec:compiler-description]] prezentuje implementację kompilatora języka =FOOF= wymieniając kolejne fazy kompilacji oraz opisując i motywując wykorzystane w nich algorytmy i techniki programistyczne. Opisowi towarzyszy dyskusja alternatywnych podejść i możliwych usprawnień.

Rozdziały [[ref:sec:runtime-system]] oraz [[ref:sec:knowledge-engineering]] szczegółowo opisują implementację środowiska uruchomieniowego języka =FOOF=, począwszy od podstawowych procedur niezbędnych do działania programów, przez wsparcie dla programowania współbieżnego i rozproszonego oraz reprezentację i przetwarzanie wiedzy.

Rozdział [[ref:sec:outro]] zawiera podsumowanie pracy oraz krótką dyskusję na temat przyszłych kierunków rozwoju.

Dodatki [[ref:sec:foof-grammar]], [[ref:sec:foof-examples]], [[ref:sec:built-ins]] oraz [[ref:sec:misc]] zawierają odpowiednio: formalną specyfikację gramatyki języka =FOOF=, przykładowe, gotowe do uruchomienia programy, listę wbudowanych funkcji i makr oraz spisy rysunków i listingów kodu źródłowego wykorzystanych w pracy.

* Język =FOOF=
#+LaTeX: \label{sec:lang-description}

Niniejszy rozdział szczegółowo opisuje projekt języka programowania =FOOF= począwszy od podstawowych typów danych, przez notację funkcji, kontynuacji i procesów, kończąc na zaawansowanych mechanizmach języka, takich jak przetwarzanie wiedzy i wbudowany system makr. W dodatku [[ref:sec:foof-grammar]] zawarto formalny opis gramatyki języka, natomiast w dodatku [[ref:sec:foof-examples]] zamieszczono kilka przykładowych programów.

Język =FOOF= został zaprojektowany bazując na cennych wskazówkach przedstawionych przez John'a Backus'a w wykładzie wygłoszonym przez niego podczas odbierania Nagrody Turing'a w 1977 roku [[cite:Backus1978]]. Wskazówki te są ponadczasowe i stanowią dobrą podstawę do tworzenia języków programowania, a w dużym skrócie sprowadzają się do następujących punktów:

- *prostota lecz nie surowość* (ang. /simplicity, not crudeness/) - języki programowania powinny cechować się prostotą, lecz nie ograniczać ekspresywności programisty przez brak możliwości zrealizowania pewnych funkcjonalności, a co za tym idzie:

- *ortogonalne funkcjonalności* (ang. /orthogonal features/) - język programowania powinien składać się z niewielkiej liczby dobrze zdefiniowanych i dobrze współgrających mechanizmów, za pomocą których programista jest w stanie łatwo zbudować wszelkie inne potrzebne funkcjonalności.

Oczywiście, zasady te nie są wystarczające do stworzenia funkcjonalnego języka programowania, dlatego kierowano się także *pragmatyzmem*, który w kontekście projektowania języków programowania sprowadza się do podejmowania kompromisów, pomiędzy /matematyczną czystością/ a faktyczną użytecznością potencjalnych funkcjonalności dostarczanych przez język. Podejście to zostało szczegółowo opisane w [[cite:Hoare1973]].

Ze względu na podobne zasady, którymi kierowano się podczas projektowania, język =FOOF= przypomina pod względem składniowym i semantycznym odpowiednio języki *Scheme* (opisany szczegółowo w [[cite:Sperber2010]]) oraz *Standard ML* [[cite:Milner1997]]. Natomiast, cechami odróżniającymi =FOOF= od tych języków są: wsparcie dla programowania współbieżnego oraz wykorzystanie inżynierii wiedzy w celu osiągnięcia /świadomości platformy/ i rozwiązania problemu heterogeniczności systemów rozproszonych.

** Podstawowe typy danych
Listing [[ref:code:basic-data-types]] prezentuje proste typy danych dostępne w języku =FOOF=; są to podstawowe elementy budulcowe programów, które mają swoją reprezentację literałową.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Podstawowe typy danych dostępne w języku \texttt{FOOF}.}}
#+latex: \label{code:basic-data-types}
#+begin_src clojure
23.5
symbol
:symbol
"ciąg znaków"
(1 2 3)
[1 2 3]
{:a 1 :b 2}
#+end_src
#+latex: \end{listing}

Typy te to w kolejności: liczby, symbole, słowa kluczowe i ciągi znaków tekstowych, stanowiące wspólnie klasę wartości atomowych oraz listy pojedynczo-wiązane, wektory i mapy asocjacyjne. Każdy nieatomowy typ danych składa się z określonej liczby podwartości, które mogą być atomowe, lub nieatomowe. Semantyka każdego wymienionego typu danych jest zgodna z analogicznymi konstrukcjami opisanymi w [[cite:Sperber2010]].

Jako, że język =FOOF= jest dialektem języka Lisp, programy kodowane są homoikonicznie przez opisane powyżej typy danych - stosowana jest notacja *S-wyrażeń*, która została wprowadzona w [[cite:McCarthy1960]]. Notacja ta rozmywa granicę pomiędzy programami a danymi, pozwalając programom na manipulację, budowę i transformację innych programów.

Homoikoniczność i notację S-wyrażeń wykorzystano w wielu innych mechanizmach dostępnych w języku, które zostały opisane w dalszej części niniejszego rozdziału, w szczególności w implementacji systemu makr pozwalającego na rozszerzenie składni języka.

** Funkcje
Pierwszym złożonym typem danych, który nie ma reprezentacji literałowej w języku =FOOF= są funkcje. Funkcje są obiektami pierwszej klasy, to znaczy, po stworzeniu podczas działania programu, mogą być wykorzystywane tak jak każdy inny typ danych, a co za tym idzie, mogą być osadzane w listach, przekazywane do innych funkcji, a także z nich zwracane jako wynik obliczeń.

Funkcje zostały zaprojektowane w oparciu o *Rachunek Lambda*, wprowadzony w 1933 roku przez Alonzo Church'a jako alternatywny model logiki i, następnie, prowadzenia obliczeń [[cite:Church1932, Church1933]]. Rachunek ten wprowadza pojęcie *wyrażenia lambda*, które jest ekwiwalentem jednoargumentowych funkcji obecnych języków programowania, oraz szereg zasad substytucji, zwanych redukcjami, pozwalających na uproszczenie zagnieżdżonych wyrażeń lambda. Najważniejszą z wprowadzanych redukcji jest *\beta-redukcja*, która konceptualnie reprezentuje aplikację funkcji z odpowiednimi argumentami i jednocześnie pozwala na prowadzenie obliczeń.

Zasady Rachunku Lambda są fundamentalnie bardzo nieskomplikowane, a mimo to pozwalają na ekspresję skomplikowanych idei, takich jak logika Bool'a, arytmetyka, struktury danych oraz rekurencja. Na listingu [[ref:code:ex-lambda-calculus]] zawarto przykład realizacji logiki boola wraz z kilkoma operatorami logicznymi w czystym Rachunku Lambda.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład implementacji wartości i operatorów logicznych w Rachunku Lambda.}}
#+latex: \label{code:ex-lambda-calculus}
#+BEGIN_SRC text
TRUE := λx.λy.x
FALSE := λx.λy.y

AND := λp.λq.p q p
OR := λp.λq.p p q
NOT := λp.λa.λb.p b a

AND TRUE FALSE
    ≡ (λp.λq.p q p) TRUE FALSE →β TRUE FALSE TRUE
    ≡ (λx.λy.x) FALSE TRUE →β FALSE
#+END_SRC
#+latex: \end{listing}

Wartości logiczne kodowane są jako wyrażenia lambda konsumujące dwa argumenty i wybierające odpowiednio pierwszy z nich, dla logicznej wartości prawdy, lub drugi z nich, dla logicznej wartości fałszu. W podobny sposób kodowane są operatory logiczne, a wynik ich działania obliczany jest przez sukcesywne przeprowadzanie substytucji nazwy argumentu na jego wartość oraz redukowaniu otrzymanych wyrażeń za pomocą \beta-redukcji.

Warto zauważyć, że wyrażenia lambda można interpretować jako tak zwane *domknięcia leksykalne*, czyli tworzone podczas \beta-redukcji otaczającego wyrażenia pary funkcji i map asocjacyjnych odzwierciedlających wartości zmiennych, które występują w ciele domknięcia leksykalnego, a nie są przez nie wprowadzane. Domknięcia leksykalne pozwalają opóźnić substytucję nazw argumentów wyrażeń lambda na odpowiadające im wartości, dzięki czemu są łatwiejsze w implementacji [[cite:PeytonJones1992]]. Listing [[ref:code:closures-at-work]] pokazuje działanie domknięć leksykalnych w notacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład ilustrujący działanie domknięć leksykalnych.}}
#+latex: \label{code:closures-at-work}
#+begin_src scheme
(let* ((x 23)
       (foo (lambda () x)))
  (let ((x 5))
    (display (foo)))) ;; Wyświetla liczbę 23
#+end_src
#+latex: \end{listing}

Funkcja =foo= zaprezentowana na listingu, korzysta z wartości *wolnej zmiennej* =x=, czyli takiej, której nie wprowadza w liście swoich argumentów. W dalszej części programu, funkcja =foo=, pomimo lokalnej zmiany wartości zmiennej =x=, poprawnie zwraca oryginalną jej wartość, ponieważ w momencie jej tworzenia wartość zmiennej =x= została zapisana razem z ciałem funkcji.

Często pojawiającym się problemem związanym z funkcjami wzorowanymi na Rachunku Lambda, jest tak zwany problem *funarg*, polegający na niepoprawnym działaniu programów, które zwracają funkcje jako wynik obliczeń, lub przekazują je jako argumenty innych funcji. Problem ten sprowadza się do niewłaściwego budowania domknięć leksykalnych, co może doprowadzić do przedwczesnego usunięcia wartości zmiennych wolnych. Został on poruszony w [[cite:Abelson1996]].

Kolejnym problemem towarzyszącym funkcjom zrealizowanym jako domknięcia leksykalne jest nietrywialna implementacja rekurencji, wynikająca z ustalonej kolejności wykonywania działań - tworzenie domknięcia leksykalnego funkcji rekurencyjnej jest uzależnione od jej uprzedniego istnienia, co prowadzi do sprzeczności.

Oryginalna praca wprowadzająca Rachunek Lambda w celu osiągnięcia rekurencji wykorzystuje rachunek kombinatorów [[cite:Church1932]], a w szczególności *kombinator Y*. Sposób działania tego kombinatora został szczegółowo opisany w [[cite:Felleisen1991]], natomiast problem i propozycję implementacji rekurencji szerzej opisano w [[cite:Rzepecki2015]].

** Kontynuacje
#+LaTeX: \label{sec:continuations-description}

Kolejnym mechanizmem będącym integralną częścią języka =FOOF= są kontynuacje, czyli abstrakcyjne reprezentacje przepływu sterowania programów, które pozwalają jednoznacznie określić kolejność wykonywania obliczeń.

Kontynuacje można interpretować jako ciąg obliczeń pozostałych do wykonania z punktu widzenia danego miejsca programu, który został *reifikowany* jako funkcja i udostępniony z poziomu wykonywanego programu. W efekcie, programy mogą zadecydować by zrestartować obliczenia od pewnego momentu, albo wręcz przeciwnie, przerwać je odrzucając wartości pośrednie.

Jako, że jest to mechanizm skomplikowany, który był odkrywany wielokrotnie [[cite:Reynolds1993]], często nieświadomie, istnieje wiele jego wersji i sposobów implementacji, a w związu z czym nie jest on powszechnie dostępny jako standardowa funkcjonalność popularnych języków programowania. Ze względu na swoje właściwości opisane powyżej, kontynuacje są częściej stosowane w implementacjach kompilatorów języków programowania, jako format pośredni reprezentacji programów [[cite:Appel1992]].

Języki programowania, które korzystają z kontynuacji czasem udostępniają je jako obiekty pierwszej klasy, które mogą być traktowane w taki sam sposób jak inne typy danych. Służy do tego wiele zróżnicowanych operacji prymitywnych, które różnią się semantyką. W przypadku języka Scheme operacja prymitywna służąca do przechwytywania kontynuacji to =call-with-current-continuation= (=call/cc=) [[cite:Sperber2010]], natomiast w języku Standard ML służy ku temu konstrukcja =letcc= [[cite:Harper1998]].

Istnieją także sposoby komponowania kontynuacji, bazujące na tak zwanych kontynuacjach ograniczonych (ang. /delimited continuations/), które wykorzystują większą liczbę operacji prymitywnych, na przykład =shitf= oraz =reset= opisane w [[cite:Dybvig2005]], w celu zapewnienia większej kontroli nad przepływem sterowania programu. Listing [[ref:code:ex-early-return]] demonstruje sposób wykorzystania kontynuacji w języku =FOOF= w celu implementacji wczesnego powrotu z funkcji.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład wykorzystania kontynuacji w języku \texttt{FOOF}.}}
#+latex: \label{code:ex-early-return}
#+begin_src scheme
(lambda (x)
  (letcc return
    ...
    (return 23)
    ...))
#+end_src
#+latex: \end{listing}

Dzięki możliwości przechwycenia kontynuacji, program jest w stanie przedwcześnie zakończyć działanie funkcji z obliczoną wartością. Kontynuacje dostępne są bezpośrednio, dzięki konstrtukcjom =letcc=, =shift= oraz =reset=, a także pośrednio, dzięki gamie innych mechanizmów kontroli przepływu sterowania, takich jak obsługa błędów, czy multiprocessing.

Alternatywną metodą osiągnięcia podobnej funkcjonalności do tej oferowanej przez kontynuacje jest wykorzystanie /koprocedur/, czyli generalizacji funkcji pozwalającej na bezpieczne przerwanie działania w określonych miejscach i późniejszego do nich powrotu [[cite:Moura2009]]. Rozwiązanie to wymaga jednak sprecyzowania miejsc powrotu przez programistę, zwykle za pomocą konstrukcji =yield= lub =async/await=, co jest mniej ekspresywne niż wykorzystanie pełnych kontynuacji.

** Obsługa błędów
Jednym z najważniejszych mechanizmów, jakie powinien udostępniać język programowania, jest mechanizm obsługi błędów i sytuacji wyjątkowych.

Język =FOOF= zapewnia mechanizm obsługi błędów, który bazuje na kontynuacjach, w związku z czym charakteryzuje się bardzo dużą ekspresywnością. Mechanizm ten umożliwia, analogicznie do większości popularnych języków programowania, zadeklarowanie procedury obsługi zdarzeń wyjątkowych za pomocą konstukcji =handle= oraz sygnalizację zajścia takiego zdarzenia poprzez =raise=.

W przeciwieństwie do większości języków programowania, mechanizm dostępny w języku =FOOF= pozwala na kontynuowanie obliczeń w miejscu wystąpienia błędu z nową wartością, obliczoną w zadeklarowanej procedurze obsługi błędu. Przykład ilustrujący taki schemat został zaprezentowany na listingu [[ref:code:ex-restarts]].

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład wykorzystania mechanizmu obsługi błędów.}}
#+latex: \label{code:ex-restarts}
#+begin_src scheme
(handle (do ...
            (raise 'error) ;; Błąd w trakcie wykonywania obliczeń.
            ...)
        (lambda (error restart)
          ...
          (restart new-value))) ;; Kontynuacja z nową wartością.
#+end_src
#+latex: \end{listing}

Przykładowy program deklaruje procedurę obsługi sytuacji wyjątkowej, a następnie przechodzi do kosztownych obliczeń, które przedwcześnie sygnalizują wystąpienie błędu. Przepływ sterowania zostaje przekazany do zadeklarowanej procedury obsługi sytuacji wyjątkowej, która decyduje się zrestartować obliczenia dostarczając im nową, poprawną wartość. Następnie, program wraca do punktu wystąpienia błędu i kontynuuje obliczenia wykorzystują nową, poprawną wartość.

** Przetwarzanie współbieżne i rozproszone
#+LaTeX: \label{sec:actor-model-description}

Jednym z głównych założeń języka jest wsparcie dla przetwarzania współbieżnego i rozproszonego, dlatego istotnym jest, by abstrakcja to umożliwiająca była prosta, ekspresywna i wygodna w użyciu, ponieważ będzie stanowiła kluczowy element każdego programu, który powstanie w języku =FOOF=. Abstrakcją, która spełnia wszystkie te wymogi jest *Model Aktorowy* zaproponowany przez Carl'a Hewitt'a w 1973 roku [[cite:Hewitt1973]] i rozszerzony o formalny opis semantyki przez Williama Clingera w roku 1981 [[cite:Clinger1981]].

Model Aktorowy bazuje na kilku prostych koncepcjach, takich jak podział programu na wiele działających wspłóbieżnie procesów (aktorów), porozumiewających się poprzez przesyłanie wiadomości, na których podstawie mogą podejmować lokalne decyzje, tworzyć kolejne procesy, lub wysyłać kolejne wiadomości. Listing [[ref:code:ex-actor-model-usage]] prezentuje wszystkie operacje prymitywne udostępniane przez Model Aktorowy.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład wykorzystania prymitywnych operacji Modelu Aktorowego w języku.}}
#+latex: \label{code:ex-actor-model-usage}
#+begin_src scheme
(send (spawn (lambda ()
               (sleep 1000)
               (send (recv) 'message)))
      (self))

(equal? (recv) 'message)
#+end_src
#+latex: \end{listing}

Program ten tworzy nowy proces korzystając z funkcji =spawn=, któremu natychmiastowo wysyła wiadomość za pośrednictwem funkcji =send=, zawierając w niej swój identyfikator =self=, po czym przechodzi do oczekiwania na odpowiedź wywołując funkcję =recv=. Tymczasem, nowopowstały proces zostaje uśpiony na 1000 milisekund (=sleep=) po czym odbiera przesłaną do niego wiadomość i odpowiada na nią wysyłając symbol =message=.

Interfejs ten jest bardzo zbliżony do interfejsu Modelu Aktorowego dostępnego w języku Erlang [[cite:Armstrong1996]] i zaiste był na nim wzorowany. W odróżnieniu od języka Erlang, odbieranie wiadomości nie wykorzystuje dopasowywania wzorców bezpośrednio w prymitywnej operacji =recv=, lecz umożliwia jego osobną implementację. Podobnie, jak w przypadku języka Erlang, projekt przewiduje rozszerzenie listy prymitywnych operacji o identyfikację maszyn, na których działają procesy.

Implementacja Modelu Aktorowego w języku =FOOF= podobnie jak mechanizm obsługi błędów, została oparta o kontynuacje i zostanie opisana szczegółowo w następnych rozdziałach.

** Makra
#+LaTeX: \label{sec:macros-description}

Prawdobodobnie najciekawszą funkcjonalnością języków z rodziny Lisp jest ich podejście do metaprogramowania i generowania kodu. Większość języków z tej rodziny wykorzystuje wersję systemu *makr*, który pozwala rozszerzać składnię języka i tworzyć dialekty domenowe (ang. /domain specific language/) w prosty i przystępny sposób. Język =FOOF= nie jest wyjątkiem i również został wyposażony w system makr.

Listing [[ref:code:ex-macroexpansion]] prezentuje efekt działania *makroekspansji*, czyli substytucji wywołań makr na definicje ich ciał, na przykładzie kilku wbudowanych makr rozszerzających składnię języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład działania systemu makr w języku \texttt{FOOF}.}}
#+latex: \label{code:ex-macroexpansion}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Przed makroekspansją:
(and 23 42)



(let ((x 23))
  (display x))


`(4 is ,(* 2 2))
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Po makroekspansji:
(if 23
    42
    false)

((lambda (x)
   (display x))
 23)

(list '4 'is (* 2 2))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Efektem makroekspansji jest powstanie semantycznie ekwiwalentnego kodu, który wykorzystuje tylko dobrze zdefiniowane konstrukcje składniowe języka. Warto zwrócić uwagę na ostatni z przykładów, który prezentuje znaną z innych dialektów języka Lisp konstrukcję =quasiquote=. Konstrukcja ta umożliwia budowanie programów w łatwy, wizualny sposób bez konieczności samodzielnego budowania drzew programu z wykorzystaniem funkcji =cons=, =list= i pokrewnych. Szczegółowy opis działania =quasiquote= został zawarty w [[cite:Bawden1999]].

Systemy makr czesto borykają się z problemami *higieniczności* generowanego kodu. Problem ten ilustruje przykład z listingu [[ref:code:macro-hygiene]].

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład ilustrujący problem higieniczności systemu makr w języku Scheme.}}
#+latex: \label{code:macro-hygiene}
#+begin_src scheme
(define-macro (unless c . b)
  `(if (not ,c)
       (begin ,@b)
       #void))

(let ((not identity))
  (unless #t
    (display "Hello world!")))
#+end_src
#+latex: \end{listing}

Zdefiniowane zostaje makro =unless=, którego zadaniem jest uruchamianie pewnych obliczeń jedynie, gdy podany warunek nie jest spełniony. W tym celu makro korzysta z konstrukcji =if= oraz funkcji =not=, nie zachowując, niestety, higieniczności, czego dowodzi druga część przykładu - lokalna zmiana wartości zmiennej =not= na funkcję tożsamości powoduje niewłaściwe działanie makra =unless=.

Problem higieniczności jest problemem skomplikowanym i zazwyczaj jego rozwiązanie oznacza poświęcenie części funkcjonalności systemu makr, na przykład poprzez ograniczenie go do translacji szablonów [[cite:Sperber2010]], lub znacznego jego skomplikowania, przez konieczność wprowadzenia hierarchicznej refleksji makroekspansji [[cite:Queinnec1996]]. Niestety, system makr języka =FOOF= pozostawia ten problem otwartym.

Alternatywnym podejściem do problemu metaprogramowania, o którym warto wspomnieć są *f-wyrażenia* (ang. /f-expressions/, /fexprs/), polegające na podziale funkcji na dwa fundamentalne kompotenty - aplikatywny, indukujący ewaluację argumentów oraz operatywny, analogiczny do substytucji nazw argumentów na ich wartości w wyrażeniach lambda Rachunku Lambda [[cite:Shutt2010]]. Podejście to drastycznie komplikuje kompilację kodu źródłowego, w związku z czym nie zostało wykorzystane w języku =FOOF=.

** System modułowy
#+LaTeX: \label{sec:module-system}

W celu umożliwienia podziału kodu źródłowego programów na logicznie związane części i ułatwienia zarządzania nimi, nowoczesne języki programowania często udostępniają systemy modułowe, wraz z niezbędnymi do ich działania rozszerzeniami składniowymi.

Systemy takie, w zależności od języka programowania, na potrzeby którego zostały zaprojektowane, różnią się sposobem działania oraz ekspresywnością. Mniej skomplikowane systemy modułowe polegają na zwyczajnych podstawieniach tekstowych z opcjonalnym wsparciem dla /przestrzeni nazw/ w celu uniknięcia konfliktów identyfikatorów, natomiast bardziej skomplikowane umożliwiają kontrolę dostępu oraz definiowanie zależności pomiędzy poszczególnymi modułami.

System modułowy wykorzystywany w języku =FOOF= jest zbliżony w swojej funkcjonalności do analogicznego systemu języka Standard ML [[cite:Harper1998]], a właściwe jego modyfikacji opisanej w [[cite:Rossberg2015]], gdzie mamy do czynienia ze *strukturami* wiążącymi ze sobą definicje funkcji i zmiennych, oraz *funktorami*, które pozwalają parametryzować struktury. Listing [[ref:code:ex-module-system-usage]] prezentuje przykład wykorzystania systemu modułowego języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład wykorzystania systemu modułowego języka \texttt{FOOF}.}}
#+latex: \label{code:ex-module-system-usage}
#+begin_src scheme
(structure A
 (define (foo x)
   (+ 23 x)))

(module (B a)
  (define (bar)
    (a.foo 5)))

(let ((b (B A)))
  (display (b.bar))) ;; Wyświetla liczbę 28
#+end_src
#+latex: \end{listing}

W przykładzie definiowana jest struktura =A= dostarczającą funkcję =foo= oraz moduł (odpowiednik funktora) =B= parametryzowany przez submoduł =a=. Następnie, tworzona jest instancja modułu =B=, wykorzystując zdefiniowaną uprzednio strukturę =A=, i używana w dalszej części programu. Korzystanie z sytemu modułowego jest ułatwione, dzięki specjalnej składni dostępu do zawartości modułu =module.member=.

System ten pozwala w łatwy sposób zarządzać zależnościami modułów - wystarczy zmienić parametr przekazany przy tworzeniu instancji modułu =B= na inną strukturę, bez modyfikacji jego definicji, by osiągnać zamierzone cele. Funkcjonalność ta jest bardzo przydatna przy tworzeniu bibliotek programistycznych, które mogą być parametryzowane modułami służącymi do powszechnych zadań, takimi jak moduł do logowania, lub moduł zawierający parametry konfiguracji aplikacji. W efekcie, biblioteki te nie narzucają z góry implementacji modułów parametryzujących, dzięki czemu mogą być łatwiej zintegrowane z różnymi programami.

Zasadniczą wadą systemu modułowego w zaprezentowanej powyżej formie, jest konieczność istnienia osobnej fazy *linkowania*, czyli tworzenia instancji modułów. Problem ten został szczegółowo przeanalizowany w [[cite:Gasbichler2006]], skutkując stworzeniem notacji /interfejsów modułów/ ułatwiającej automatyczną rezolucję zależności. Rozwiązanie to jest dalekie od doskonałego, toteż język =FOOF= stosuje inne podejście opisane w sekcji [[ref:sec:knowledge-engineering-description]].

** Inżynieria wiedzy w języku
#+LaTeX: \label{sec:knowledge-engineering-description}

Ostatnią i zarazem najbardziej zaawansowaną funkcjonalnością języka =FOOF= jest jego wsparcie dla inżynierii wiedzy (ang. /knowledge engineering/), objawiające się umożliwieniem refleksji na podstawie pewnych /informacji/, które zostały odkryte podczas działania programów. Wspomniane, powiązane ze sobą logicznie informacje, czyli *wiedza*, mogą dotyczyć wielu różnych aspektów działania aplikacji i są w dużej mierze uzależnione od domeny rozwiązywanych problemów.

Istnieje wiele metod reprezentacji i przetwarzania wiedzy, które różnią się sposobem dostępu do zdobytych informacji, a co za tym idzie, stosownością do rozwiązywania danych klas problemów [[cite:Wang2013]]. Dlatego też, wybór konkretnej reprezentacji i mechanizmu przetwarzania wiedzy w języku =FOOF= uzależniony jest od pragmatycznego jego zastosowania.

Wiodącym zadaniem inżynierii wiedzy w języku =FOOF= jest realizacja jednego z główych założeń języka, czyli osiągnięcia *świadomości platformy* poprzez zdobycie i udostępnienie wiedzy o platformie sprzętowej i samej aplikacji na niej działającej. Wiedza ta ma stanowić bazę do podejmowania decyzji o rozwoju obliczeń prowadzonych w aplikacji, a także o samej strukturze systemu.

W założeniu ma to umożliwić automatyczną konfigurację i ewolucję rozproszonych aplikacji zbudowanych z wykorzystaniem języka =FOOF=. Na przykład, system inteligentnego domu, po wykryciu podłączenia w odpowiednim pomieszczeniu czujnika temperatury o wyższej dokładności pomiarów niż dotychczasowo dostępna, powinien bez modyfikacji programu, ani ingerencji jego użytkownika, zacząć z niego korzystać. Natomiast, w przypadku katastrofalnego błędu rzeczonego czujnika, system powinien wrócić do korzystania z poprzedniego czujnika.

Literatura związana z tą dziedziną nauki, która zarazem dotyczy systemów rozproszonych o wysokiej heterogeniczności, takich jak Internet Rzeczy, bardzo często wykorzystuje podejście ontologiczne [[cite:Hachem2011, Wang2013, Samimi2014]]. Polega ono na budowie ontologii domenowej na potrzeby systemu, gdzie wiedza jest reprezentowana jako instancje i klasy obiektów powiązanych ze sobią pewnymi zależnościami. Ontologia ta może być następnie odpytywana, a działający w niej algorytm rozumowania (ang. /reasoner/) pozwala odkrywać nowe zależności pomiędzy obiektami.

Rozwiązane to wchodzi w konflikt z założeniami języka =FOOF= przez swoje skomplikowanie, relatywną restrykcyjność i statyczność bazy wiedzy oraz kosztowność obliczeniową, toteż, pomimo niewątpliwych zalet, nie mogło zostać wdrożone. Alternatywnym rozwiązaniem zastosowanym w języku jest podejście regułowe, polegające na reprezentacji wiedzy w formie *faktów* o nienarzuconej strukturze i przetwarzaniu tej wiedzy za pomocą *reguł* weryfikujących ową strukturę. Listing [[ref:code:ex-rbs-usage]] pokazuje podstawowe operacje związane z inżynierią wiedzy dostępne w języku =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład wykorzystania prymitywnych operacji bazy wiedzy w języku.}}
#+latex: \label{code:ex-rbs-usage}
#+begin_src scheme
(whenever set-of-conditions
  (lambda (_)
    (retract! some-fact)
    (assert! another-fact)))
(signal! an-event)
#+end_src
#+latex: \end{listing}

Przykład ten definiuje jedną regułę bez zagłębiania się w szczegóły implementacji systemu regułowego języka =FOOF=. Reguła ta, bazując na spełnialności pewnego zbioru warunków =set-of-conditions= modyfikuje wbudowaną bazę faktów przez *asercję* i *retrakcję* rożnych faktów. Dodatkowo, przykład *sygnalizuje* zaistnienie pewnego zdarzenia =an-event=, co konceptualnie jest tożsame z asercją i późniejszą retrakcją faktu opisującego zajście tego zdarzenia w systemie.

Projekt przewiduje wykorzystanie opisanych powyżej podstawowych operacji oraz wiedzy możliwej do zdobycia podczas kompilacji programów języka =FOOF= poprzez *inferencję* faktów dotyczących struktury ich kodu źródłowego, do rozwiązania opisanego w sekcji [[ref:sec:module-system]] problemu linkowania modułów. Rozwiązanie to polega na przetworzaniu inferowanej wiedzy za pomocą zbioru reguł, zwanych kolektywnie *protokołem modułu*, w celu rezolucji zależności je spełniających w sposób automatyczny. Moduły, zamiast dokładnego sprecyzowania swoich zależności, mogą podać protokóły, które są konieczne i wystarczające do poprawnego, wspólnego działania, a system regułowy automatycznie wybierze spełniające je, dostępne submoduły.

* Kompilator języka =FOOF=
#+LaTeX: \label{sec:compiler-description}

Niniejszy rozdział przedstawia implementację kompilatora języka programowania =FOOF= szczegółowo opisując jego architekturę i poszczególne fazy kompilacji programów.

Kompilator jest programem komputerowym, którego głównym zadaniem jest *transformacja kodu źródłowego* programów do formatu bardziej odpowiedniego do uruchomienia przez maszynę [[cite:Aho2006]]. Wynikiem działania kompilatora jest najczęściej plik wykonywalny zawierający instrukcje możliwe do uruchomienia przez procesor lub /maszynę wirtualną/, w przypadku kompilatorów /kodu bajtowego/. Kompilacja jest zwykle podzielona na kilka osobnych faz, takich jak analiza leksykalna, analiza semantyczna, optymalizacja i generacja kodu, które różnią się typem i celem przeprowadzanych transformacji [[cite:Aho2006]].

Kompilator języka =FOOF= jest w założeniu kompilatorem /kodu maszynowego/, wynikiem działania którego jest strumień instrukcji możliwych do uruchomienia przez procesor komputera. Niestety, w wyniku ograniczeń czasowych i samej wielkości takiego projektu, ostatnie fazy kompilacji odpowiedzialne za generację kodu maszynowego zostały pominięte, a kompilacja programów kończy się na uruchamialnej reprezentacji pośredniej programów.

Towarzyszący pracy program został napisany w sposób inkrementalny [[cite:Ghuloum2006]] z wykorzystaniem wspólnego podzbioru języków Scheme oraz =FOOF=, celem późniejszego osiągnięcia auto-kompilacji (ang. /bootstrapping compiler/). Podczas tworzenia kompilatora nieocenione okazały się wskazówki na temat implementacji /języków funkcyjnych/, do których należy również język =FOOF=, przedstawione w [[cite:PeytonJones1992]].

** Architektura kompilatora
Architektura kompilatora języka =FOOF= jest typowa dla tego typu programów [[cite:Aho2006]], kompilacja została podzielona na jeden przebieg, na który składa się kilka logicznie po sobie następujących faz. Schemat [[ref:fig:compilation-phases]] prezentuje obecnie zaimplementowane w kompilatorze fazy oraz te, których implementacja została przewidziana w przyszłości, wraz z przykładami pośrednich reprezentacji programów w nich występujących.

#+begin_center
#+label: fig:compilation-phases
#+caption: Schemat poszczególnych faz kompilacji i przykładowych danych będących wynikiem ich działania.
#+attr_latex: :width 1.0\textwidth :placement [H]
[[file:./img/compilationphases.pdf]]
#+end_center

Pierwszą fazą jest faza *analizy leksykalnej i syntaktycznej* polegająca na transformacji kodu źródłowego - tekstu enkodującego programy - do formatu wewnętrznego możliwego do przetworzenia przez następne fazy kompilacji. Analiza syntaktyczna wykorzystuje opisaną w rozdziale [[ref:sec:lang-description]] homoikoniczność języka =FOOF= i reprezentuje programy jako drzewa zbudowane z podstawowych typów danych dostarczanych przez język.

Druga faza kompilacji to faza *makroekspansji* polegająca na uproszczeniu konstrukcji syntaktycznych występujących w programach za pomocą szeregu transformacji. Faza ta pozwala uprościć analizę semantyczną pojawiającą się w późniejszych fazach kompilacji dzięki redukcji liczby różnych konstrukcji języka, które muszą być brane pod uwagę.

Trzecią fazą jest faza *konwersji /Continuation Passing Style/* polegająca na syntaktycznej transformacji kodu źródłowego programów celem wplecenia do niego *kontynuacji* [[cite:Appel1992]]. Reprezentacja pośrednia programów po tej fazie kompilacji różni się zasadniczo od dotychczasowej reprezentacji, dzięki czemu ułatwia implementację szeregu opisanych wcześniej funkcjonalności języka.

Ostatnie dwie fazy kompilacji, czyli fazy *optymalizacji* i *generacji kodu maszynowego* w dużej mierze polegają na uproszczeniu przetworzonego kodu programów i przetłumaczeniu go na strumień prostych instrukcji możliwych do uruchomienia przez procesor komputera.

Kompilator działa w pojedynczym przebiegu, podczas którego każda z faz jest uruchamiana dokładnie jeden raz. Szczegółowy opis działania i implementacji poszczególnych faz został zawarty w dalszej części rozdziału.

** Parsowanie
Pierwszym logicznym elementem kompilatora jest *parser* przeprowadzający analizę leksykalną i syntaktyczną. Jego zadaniem jest transformacja tekstu reprezentującego programy języka =FOOF= do drzewiastej reprezentacji bazującej na podstawowych typach danych udostępnianych przez język.

W związku z wyborem technologii wykorzystanych do implementacji kompilatora, budowa parsera przez niego używanego została oparta o, będące częścią standardu języka Scheme, podstawowe funkcje operujące na plikach i kodzie źródłowym, takie jak =with-input-from-file= oraz =read= [[cite:Sperber2010]]. Implementacja dedykowanych parserów jest żmudna i nie prezentuje zbyt wysokiej wartości poznawczej, natomiast tworzenie generatora parserów, pomimo niewątpliwej ciekawości i przydatności z punktu widzenia użyteczności języka programowania, nie stanowi tematu niniejszej pracy. Powstała implementacja jest więc minimalną wersją niezbędną do umożliwienia dalszej kompilacji programów.

Opisany parser wspiera podstawową składnię języka =FOOF= wynikającą z jego homoikoniczności oraz jedno rozszerzenie składniowe usprawniające generowanie programów wewnątrz kompilatora. Rozszerzenie to polega na transformacji kombinacji znaków specjalnych \texttt{'}, =`=, \texttt{,} oraz \texttt{,@} do odpowiadających im konstrukcji w formacie S-wyrażeń. Listing [[ref:code:ex-syntax-expansion]] pokazuje kod źródłowy i kod powstały po ekspansji syntaktycznej przeprowadzonej przez parser.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Obsługa rozszerzeń składniowych S-wyrażeń w języku \texttt{FOOF}.}}
#+latex: \label{code:ex-syntax-expansion}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Kod źródłowy:
'(some value)
`(a ,b ,@c)
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Po ekspansji:
(quote (some value))
(quasiquote (a (unquote b)
               (unquote-splicing c)))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Należy zauważyć, że ekspansja syntaktyczna powyższego rozszerzenia składniowego nie jest jednoznacza z ekspansją wynikającą z jego znaczenia, która jest przeprowadzana w fazie makroekspansji opisanej w sekcji [[ref:sec:macroexpansion-impl]].

Naturalnie, istnieje możliwość łatwej wymiany implementacji parsera w przyszłości na mechanizm bardziej rozbudowany, wspierający dowolną ilość rozszerzeń składniowych. Można do tego celu wykorzystać generator parserów zbudowany w oparciu o gramatyki PEG (ang. /Parsing Expression Grammars/) [[cite:Ford2004]] oraz monadyczne kombinatory parserów [[cite:Hutton1996]], które szczególnie dobrze nadają się do budowy parserów dla języków o nieskomplikowanej podstawowej gramatyce, takich jak =FOOF=.

** Makroekspansja
#+LaTeX: \label{sec:macroexpansion-impl}

Pierwszą fazą transformującą w znaczący sposob kod źródłowy języka =FOOF=, jest faza makroekspansji. Jej głównym zadaniem jest umożliwienie istnienia opisanego w rozdziale [[ref:sec:lang-description]] systemu makr, a polega ona na aplikacji definicji makr do fragmentów kodu źródłowego znajdujących się w miejscu ich wywołań. Listing [[ref:code:macro-expansion-pseudocode]] prezentuje pseudokod algorytmu realizującego fazę makroekspansji w notacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Pseudokod algorytmu makroekspansji w notacji języka \texttt{FOOF}.}}
#+latex: \label{code:macro-expansion-pseudocode}
#+begin_src scheme
(define (macroexpand expression defined-macros)
  (if (and (list? expression)
           (not (quote? expression)))
      (if (macro-defined? (macro-name expression) macros)
          (macroexpand (apply-expander (macro-name expression)
                                       defined-macros
                                       expression)
                       defined-macros)
          (map (lambda (subexpression)
                 (macroexpand subexpression macros))
               expression))
      expression))
#+end_src
#+latex: \end{listing}

Algorytm ten jest rekurencyjny i przebiega w następujący sposób:

- Jeśli wyrażenie jest listą, której pierwszy element jest nazwą zdefiniowanego uprzednio makra, to następuje makroekspansja wyrażenia otrzymanego przez aplikację definicji makra do owego wyrażenia.

- Jeśli wyrażenie jest listą, ale jej pierwzy element nie identyfikuje zdefiniowanego uprzednio makra, to następuje makroekspansja każdego podwyrażenia wchodzącego w skład tego wyrażenia.

- Jeśli wyrażenie nie jest listą to zostaje zwrócone bez zmian.

Powyższy algortym uwzględnia możliwość, w której analizowanym wyrażeniem jest specjalna formuła =(quote ...)= przerywająca makroekspansję. Podobnie jak w przypadku wyrażeń nie będących listami, formuła =(quote ...)= zostaje zwrócona bez zmian. Algorytm uwzględnia również sytuację, w której wynikiem ekspansji jednego makra jest wywołanie innego makra, dzięki rekurencyjnemu wywołaniu makroekspansji po aplikacji definicji makra. Sytuację tę obrazuje listing [[ref:code:ex-macro-expansion-steps]].

W przykładzie została wykorzystana konstrukcja =let*=, która semantycznie oznacza zagnieżdżoną deklarację zmiennych lokalnych =a= oraz =b=. Makro odpowiedzialne za ekspansję konstrukcji =let*= skutkuje wygenerowaniem dwóch wywołań makra =let=, które następnie jest zamieniane na wywołania funkcji anonimowych (tworzonych za pomocą konstrukcji =lambda=) z odpowiednimi parametrami.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład działania algorytmu makroekspansji.}}
#+latex: \label{code:ex-macro-expansion-steps}
#+begin_src scheme
;; Kod źródłowy:
(let* ((a 23)
       (b (+ a 5)))
  (* 2 b))

;; Pierwszy krok makroekspansji:
(let ((a 23))
  (let ((b (+ a 5)))
    (* 2 b)))

;; Drugi krok makroekspansji:
((lambda (a)
   (let ((b (+ a 5)))
     (* 2 b)))
 23)

;; Trzeci krok makroekspansji:
((lambda (a)
   ((lambda (b)
      (* 2 b))
    (+ a 5)))
 23)
#+end_src
#+latex: \end{listing}

Obecna implementacja nie wspiera definiowania nowych makr przez użytkowników języka =FOOF=. Powodem tej niedogodności jest nietrywialna interakcja systemu makr i systemu modułów zastosowanego w języku, która została szczegółowo przeanalizowana w [[cite:Gasbichler2006]]. System makr do poprawnego funkcjonowania wymaga znajomości definicji makr, które znajdują się w różnych modułach, przed uruchomieniem programu, natomiast system modułowy wymaga uruchomienia programu w celu przeprowadzenia linkowania modułów. Rozwiązanie tego problemu jest nietrywialne, w związku z czym nie zostało uwzględnione w projekcie języka. Lista predefiniowanych makr dostępnych w języku =FOOF= została zawarta w dodatku [[ref:sec:built-ins]].

Innym problemem manifestującym się w wielu systemach makr jest opisany w sekcji [[ref:sec:macros-description]] problem higieniczności, polegający na nieoczekiwanej injekcji nieprawidłowych wartości do kodu generowanego przez makra. W zwązku z opisaną powyżej niedogodnością, problem ten nie jest obecny w implementacji języka =FOOF= i jego rozwiązanie stanowi problem otwarty. Znanych jest kilka sposobów rozwiązania problemu higieniczności systemu makr, na przykład wykorzystanie specjalnego systemu typów [[cite:Bawden2000]], lub wieży refleksji makroekspansji [[cite:Queinnec1996]].

** Obsługa systemu modułowego
Implementacja systemu modułowego języka =FOOF= wymaga niewielkiego wsparcia, w chwili obecnej, ze strony kompilatora.

Możliwość definiowania modułów została zreazilowana z wykorzystaniem systemu makr jako wywołania makr =structure= oraz =module= odpowiadające odpowiednio strukturom i funktorom opisanym w sekcji [[ref:sec:module-system]]. Makra te generują wywołania specjalnej funkcji =&make-structure= budującej struktury z prostych wartości. Listing [[ref:code:ex-module-expansion]] prezentuje wynik makroekspansji makra =module=, której pośrednim krokiem jest ekspansja makra =structure=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład ekspansji makra \texttt{module}.}}
#+latex: \label{code:ex-module-expansion}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Kod źródłowy:
(module (X a b)
  (define (foo x)
    ...)
  (define (bar y)
    ...))
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Po makroekspansji:
(define (X a b)
  (letrec ((foo (lambda (x)
                  ...))
           (bar (lambda (y)
                  ...)))
    (&make-structure
     'foo foo
     'bar bar)))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Definicje należące do zdefiniowanego modułu =X= transformowane są do postaci wzajemnie rekurencyjnej za sprawą konstrukcji =letrec=, a następnie ich wartości łączone są w jeden obiekt struktury. Do definicji należących do tak otrzymanej wartości można odnosić się z wykorzystaniem specjalnej składni =module.member=, która została zrealizowana jako ekspansja symboli w fastępnej fazie kompilacji opisanej w sekcji [[ref:sec:cps-impl]]. Wywołanie funkcji =bar= instancji =x= modułu =X= wygląda więc następująco: =(x.bar 23)=.

** Transformacja /Continuation Passing Style/
#+LaTeX: \label{sec:cps-impl}

Kolejną fazą kompilacji jest faza konwersji przekazywania kontynuacji (ang. /Continuation Passing Style/, /CPS/) polegająca na automatycznej transformacji kodu źródłowego programu do formatu, w którym wszystkie funkcje przyjmują dodatkowy argument będący sukcesywnie przekazywaną dalej kontynuacją [[cite:Appel1992]].

Celem tej fazy jest wplecenie notacji kontynuacji opisanych w sekcji [[ref:sec:continuations-description]] do pośredniej reprezentacji programów. Listing [[ref:code:ex-cps-principle]] prezentuje przykład konwersji CPS prostej funkcji.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład konwersji \textit{Continuation Passing Style}.}}
#+latex: \label{code:ex-cps-principle}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Styl bespośredni:
(lambda (x y)
  (* 2 (+ x y)))
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Styl Continuation Passing:
(lambda (x y cont)
  (__+ x y
       (lambda (v)
         (__* 2 v cont))))

;; Konwersja wbudowanych funkcji:
(define (__+ a b cont)
  (cont (+ a b)))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Po transformacji, funkcja ta przyjmuje dodatkowy argument =cont=, który następnie przekazuje dalej w ciągu obliczeń. Analogicznie, wbudowane funkcje dodawania =+= i mnożenia =*= również przyjmują dodatkowy argument, który wywołują z wynikiem odpowiedniej operacji, powodując aplikację kontynuacji.

W przykładzie można zauważyć doprecyzowanie kolejności wykonywania działań po transformacji CPS - pierwszą wykonaną operacją jest dodawanie, a jego wynik przekazywany jest do, specjalnie w tym celu stworzonej, kontynuacji pośredniej i następnie od operacji mnożenia wraz z kontynuacją =cont= wywołania funkcji.

Algorytm automatycznej konwersji CPS polega na analizie struktury kodu źródłowego metodą /dziel i zwyciężaj/ i przeprowadzeniu serii prostych podstawień, z których najważniejsze to:

- Transformacja identyfikatorów przebiega przez dodanie prefixu =__= i unormowanie znaków specjalnych w celu wyraźnego odseparowania wartości przed i po konwersji.

- Transformacja wartości prostych polega na wywołaniu /aktualnej kontynuacji/ z ich wartością.

- Transformacja funkcji polega na rozszerzeniu listy ich argumentów o dodatkowy argument reprezentujący /kontynuację wywołania funkcji/ i rekurencyjnym przeprowadzeniu transformacji ciała funkcji przy jednoczesnej podmianie aktualnej kontynuacji na wprowadzoną uprzednio kontynuację wywołania funkcji.

Dokłady opis algorytmu konwersji /Continuation Passing Style/ zawarto w [[cite:Appel1992]]. Ponieważ konwersja CPS ma miejsce podczas kompilacji i przed uruchomieniem programu, toteż wartość /aktualnej kontynuacji/ nie jest ustalona. W związku z tym, powyższy *algorytm generuje kod*, który będzie się składał na faktyczną wartość aktualnej podczas uruchomienia programu kontynuacji.

Jedną z cech konwersji CPS jest dokładne sprecyzowanie kolejności zachodzenia operacji w transfomowanych programach, co uwydatnia problem implementacji rekurencji. Zgodnie z opisem problemu z sekcji [[ref:sec:continuations-description]], funkcje rekurencyjne (a także funkcje wzajemnie-rekurencyjne) wymagają istnienia własnej (pośrednio w przypadku funkcji wzajemnie-rekurencyjnych) wartości zanim będą mogły zostać zbudowane, co prowadzi do powstania sprzeczności. Nie jest to jednak do końca prawdziwe stwierdzenie, otóż funkcje rekurencyjne wymagają pewnej *lokacji*, w której znajdzie się ich wartość, podczas budowy tejże wartości, dzięki czemu ich implementacja jest możliwa. Listing [[ref:code:cps-letrec]] prezentuje wynik transformacji CPS konstrukcji =letrec= służącej do definiowania wzajemnie-rekurencyjnych funkcji.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład transformacji konstrukcji \textt{letrec}.}}
#+latex: \label{code:cps-letrec}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
(letrec ((even? (lambda (x)
                  ...
                  odd?
                  ...))
         (odd? (lambda (x)
                 ...
                 even?
                 ...)))
  (even? 7))
#+end_src
#+LaTeX: \columnbreak
#+BEGIN_SRC scheme
(let ((__even? nil)
      (__odd? nil))
  (set! __even? (lambda (x)
                  ...
                  __odd?
                  ...))
  (set! __odd? (lambda (x)
                 ...
                 __even?
                 ...))
  (__even? 7
           (lambda (value)
             value)))
#+END_SRC
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Transformacja CPS w tym przypadku umożliwia implementację funkcji rekurencyjnych tworząc dla ich wartości lokacje (=__even?= oraz =__odd?=), do których następnie wpisuje za pomocą konstrukcji =set!= zbudowane wartości. W efekcie, obie funkcje mają wszystkie niezbędne informacje i mogą korzystać z pozostałych funkcji wprowadzonych przez konstrukcję =letrec=. Rozwiązanie to jest analogiczne do techniki opisanej w [[cite:German1995]] oraz stanowi preferowalną (pod warunkiem dopuszczenia istnienia mutacji w języku) alternatywę dla wykorzystania kombinatora =Y= [[cite:Felleisen1991]], którego implementacja dla funkcji wzajemnie-rekurencyjnych jest nietrywialna. Innym podejściem do rozwiązania problemu rekurencji jest automatyczna eliminacja wzajemnej rekursji [[cite:Kaser1993]].

Warto zauważyć, iż proste modyfikacje podstawowego algorytmu konwersji /Continuation Passing Style/, polegające na generowaniu wywołań wbudowanych funkcji w stategicznych miejscach, mogą pomóc w implementacji szerokiej gamy mechanizmów kontroli przepływu sterowania, jakich jaki obsługa błędów oraz multiprocessing. Fakt ten został wdrożony do implementacji kompilatora języka =FOOF= i szczegółowo opisany w rozdziale [[ref:sec:runtime-system]].

** Optymalizacja i generacja kodu
Ostatnie dwie fazy kompilacji to optymalizacja i generacja kodu wynikowego. Zadaniem tych faz jest uproszczenie, przyspieszenie i przygotowanie przetransformowanego w poprzednich fazach kodu do postaci możliwej do uruchomienia przez komputer.

Fazy te zostały niestety pominięte w związku z ich skomplikowaniem i ograniczeniami czasowymi nałożonymi na projekt. W chwili obecnej, kompilator języka =FOOF= kończy działanie produkując kod pośredni, będący uruchamialnym podzbiorem języków Scheme i =FOOF=, dzięki czemu może zostać uruchomiony przez interpretery i kompilatory tych języków.

W przyszłości istnieje możliwość relatywnie łatwego dodania pozostałych faz kompilacji. W szczególności, zaimplementowana już faza konwersji /Continuation Passing Style/ opisana w sekcji [[ref:sec:cps-impl]] ułatwia implementację szerokiej gamy ciekawych optymalizacji, takich jak częściowa ewaluacja statycznych wartości (ang. /partial evaluation/), prowadząca do zwijania wartości stałych (ang. /constant folding/), oraz eliminacji jednakowych podwyrażeń (ang. /common subexpression elimination/) [[cite:Bacon2002]].

Implementacja fazy generacji kodu maszynowego wymagać będzie dodatkowo *konwersji domknięć leksykalnych* (ang. /closure conversion/) i opcjonalnie *lambda-unoszenia* (ang. /lambda lifting/) [[cite:PeytonJones1992]], których zadaniem jest przeniesienie definicji funkcji anonimowych wygenerowanego kodu do globalnej przestrzeni nazw. Listing [[ref:code:lambda-lift-vs-closure-conv]] ilustruje działanie obu tych transformacji.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład ilustrujący różnice pomiędzy algorytmami lambda-unoszenia oraz konwersji domknięć leksykalnych.}}
#+latex: \label{code:lambda-lift-vs-closure-conv}
#+begin_src scheme
;; Oryginalny kod źródłowy:
(let* ((x 23)
       (plus-x (lambda (n)
                (+ n x))))
  (plus-x 5))
#+end_src
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Lambda-unoszenie:
(define (plus-x x n)
  (+ n x))

(let* ((x 23))
  (plus-x x 5))
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Konwersja domknięć-leksykalnych:
(define __lambda0 (self n)
  (+ n (&value-of self 'x)))

(let* ((x 23)
       (plus-x (&closure __lambda0
                        'x x)))
  (&apply plus-x 5))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Konwersja domknięć leksykalnych polega na przeniesieniu definicji funkcji anonimowych do globalnej przestrzeni nazw oraz odpowiedniej modyfikacji miejsc tworzenia domknięć leksykalnych. Technika lambda-unoszenia, która zwykle jest wykonywana tuż po konwersji domknięć leksykalnych, polega na redukcji ilości stworzonych obiektów funkcyjnych przez promocję zmiennych wolnych domknięć leksykalnych do listy argumentów funkcji i modyfikacji miejsc wywołań funkcji w celu przekazania dodatkowych wartości. Technika ta pozwala ominać proces budowania domknięcia leksykalnego i jednocześnie przyspieszyć miejsca jego wywołań.

* Środowisko uruchomieniowe języka
#+LaTeX: \label{sec:runtime-system}

Niniejszy rozdział przedstawia architekturę środowiska uruchomieniowego (ang. /runtime system/) języka =FOOF=, czyli środowiska zawierającego procedury niezbędne do uruchamiania programów napisanych w tym języku. Do procedur takich należą te odpowiedzialne za budowę podstawowych typów danych dostarczanych przez język programowania, procedury zarządzania pamięcią programów, a także te niezbędne do działania zaawansowanych funkcjonalności języka.

W związku ze zróżnicowaniem funkcjonalności dostępnych w różnych językach programowania, nie istnieje jedna kanoniczna metoda implementacji ich środowisk uruchomieniowych. Sytuacja jest wręcz przeciwna, dwie różne implementacje tego samego języka programowania mogą posiadać zupełnie odmienne środowiska uruchomieniowe, natomiast dwa zupełnie różne języki mogą korzystać z tego samego środowiska uruchomieniowego, co często ma miejsce w przypadku /maszyn wirtualnych/. Przykładem takiej sytuacji jest wykorzystanie maszyny wirtualnej BEAM [[cite:Armstrong1996]], oryginalnie zaprojektowanej dla języka Erlang, przez kilka innych języków programowania, takich jak Elixir i Joxa.

Język =FOOF= w obecnej postaci korzysta ze środowiska uruchomieniowego języka Scheme, rozszerzając jego funkcjonalność o mechanizmy niezbędne do implementacji przetwarzania współbieżnego, zaawansowanej obsługi błędów, a także zapewnienia wsparcia dla inżynierii wiedzy.

** Architektura środowiska uruchomieniowego
Architektura środowiska uruchomieniowego wykorzystanego w implementacji języka =FOOF= jest relatywnie nieskomplikowa i składa się z niewielkiej liczby logicznych elementów. Po części jest to zasługa wiernego podążania za zasadami projektowania języków programowania przedstawionymi w [[cite:Hoare1973]] oraz wykorzystania środowiska uruchomieniowego języka Scheme. Diagram poszczególnych elementów logicznych i ich wzajemnej interakcji został zawarty na schemacie [[ref:fig:rt-architecture]].

#+begin_center
#+label: fig:rt-architecture
#+caption: Schemat architektury środowiska uruchomieniowego języka =FOOF=.
#+attr_latex: :width 0.6\textwidth :placement [H]
[[file:./img/rtarchitecture.pdf]]
#+end_center

Konceptualnie, pamięć dostępna dla środowiska uruchomieniowego języka =FOOF= została podzielona na dwa segmenty. Pierwszy z nich, oznaczony na diagramie kolorem niebieskim, zawiera jedynie struktury danych wykorzystywane przez środowisko uruchomieniowe, takie jak kolejka i deskryptory procesów działających w systemie, czy dane systemu uruchomieniowego języka Scheme. Drugi segment pamięci, oznaczony na diagramie kolorem żółtym, stanowi pamięć operacyjna, czyli pamięć przeznaczona i dostępna dla uruchamianych programów.

Segment pamięci operacyjnej został dodatkowo podzielony na trzy obszary, dwa z których zostały zarezerwowane na obsługę implementacji systemu regułowego do przechowywania baz faktów oraz reguł (rozdział [[ref:sec:knowledge-engineering]]), a trzeci, największy z nich, stanowi główny obszar, w którym przechowywane są obiekty reprezentujące wbudowane typy danych.

Główny obszar pamięci operacyjnej programów jest wspólny dla wszystkich procesów działających w systemie (symbolizowanych na diagramie przez bloki =μProcN=), dzięki czemu możliwe jest uniknięcie nadmiernego kopiowania danych podczas przesyłania wiadomości pomiędzy procesami kosztem synchronizacji dostępu do pamięci. Podejście to, zwane *stertą współdzieloną*, jest alternatywą do podejścia zastosowanego w implementacji języka Erlang, gdzie każdy proces działa w osobnej puli pamięci, przez co wymagane jest, często kosztowne, kopiowanie struktury wiadomości [[cite:Armstrong1996]].

Obecna implementacja, w związku z ograniczeniami czasowymi narzuconymi na projekt, nie wykorzystuje pełnego potencjału przedstawionej architektury, ponieważ działa /jednowątkowo/, czyli jest ograniczona tylko do jednego wątku systemu operacyjnego. Nie ma to jednak wpływu na współbieżność procesów języka =FOOF= działających w środowisku uruchomieniowym, co zostało poruszone w sekcji [[ref:sec:cfs-impl]]. W przyszłości istnieje możliwość rozwinięcia implementacji w celu wsparcia wielowątkowości, na przykład poprzez wykorzystanie *barier pamięci*, *operacji atomowych* oraz *pamięci lokalnej dla wątku* (ang. /thread-local storage/) [[cite:McKenney2015]], co pozwoli osiągnąć przyspieszenie aplikacji języka =FOOF=.

** Implementacja podstawowych typów danych
Wybór sposóbu reprezentacji podstawowych typów danych w językach programowania jest bardzo ważny i często stanowi pole do czynienia kompromisów i optymalizacji [[cite:Aho2006]]. Języki funkcyjne, do których należy język =FOOF=, z racji swojego nacisku na przejrzystą semantykę charakteryzują się relatywną prostotą reprezentacji wbudowanych typów danych [[cite:PeytonJones1992]]. Schemat [[ref:fig:object-representation]] prezentuje przykład reprezentacji typów danych wprowadzony w [[cite:Gudeman1993]] na potrzeby języków /dynamicznie typowanych/, czyli nie weryfikujących typów zmiennych podczas kompilacji.

#+begin_center
#+label: fig:object-representation
#+caption: Schemat przykładowej reprezentacji typów danych języków funkcyjnych.
#+attr_latex: :width 0.8\textwidth :placement [H]
[[file:./img/objectrepr.pdf]]
#+end_center

Reprezentacja ta przewiduje istnienie dwóch klas obiektów:

- *prostych* - reprezentowanych przez jedno słowo procesora i posiadających krótki, trzybitowy tag określający ich dokładny typ,

-  *złożonych* - reprezentowanych przez kilka kolejnych słów procesora, z których pierwsze zawiera nieco dłuższy, ośmiobitowy tag określający ich dokłady typ oraz pewien zestaw metadanych do wykorzystania przez środowisko uruchomieniowe, a następne są obiektami prostymi.

Reprezentacja taka pozwala w łatwy sposób enkodować wszystkie podstawowe typy danych języka =FOOF=. Na przykład, listy pojedynczo-wiązane mogą być zrealizowane jako ciąg par reprezentowanych przez obiekty złożone składające się z dwóch obiektów prostych - wskaźników wskazujących na inne obiekty złożone będące elementami pary. Integracja ze środowiskiem uruchomieniowym języka Scheme pozwoliła pominąć żmudną implementację reprezentacji i procedur konstrukcji wbudowanych typów danych języka. Ich semantyka jest więc zgodna z opisem zawartym w [[cite:Sperber2010]], a ekwiwalencję składniową zaprezentowano na listingu [[ref:code:datatype-equivalence]].

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Porównanie wbudowanych typów danych języka \texttt{FOOF} i dialektu języka Scheme o nazwie Racket.}}
#+latex: \label{code:datatype-equivalence}
#+LaTeX: \begin{multicols}{2}
#+begin_src clojure
; Język FOOF:
23.5
symbol
:symbol
"ciąg znaków"
(1 2 3)
[1 2 3]
{:a 1 :b 2}
#+end_src
#+LaTeX: \columnbreak
#+begin_src scheme
;; Język Racket:
23.5
symbol
:symbol
"ciąg znaków"
(1 2 3)
#(1 2 3)
#hash((:a . 1) (:b . 2))
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Wszystkie podstawowe typy danych języka =FOOF= mają swoje dokładne, semantyczne odpowiedniki w języku Scheme, a odróżnia je jedynie reprezentacja literałowa. Warto zauważyć, iż zależość ta jest prawdziwa także dla bardziej złożonych typów danych, jak funkcje, które są kodowane w ten sam sposób. Oba środowiska uruchomieniowe różnią się natomiast reprezentacją kontynuacji - język =FOOF= używa konwersji przekazywania kontynuacji i reprezentuje je jako zwykłe funkcje - oraz brakiem idei procesów w standardzie języka Scheme.

** Implementacja kontynuacji
Implementacja kontynuacji w języku =FOOF= została zrealizowana już podczas kompilacji za sprawą automatycznej konwersji /Continuation Passing Style/, która została szczegółowo opisana w sekcji [[ref:sec:cps-impl]].

Implementacja ta pozwala reprezentować kontynuacje za pomocą zwykłych funkcji, ale w celu ułatwienia implementacji pozostałych mechanizmów kontroli przepływu sterowania, wymaga uwzględnienia pewnej modyfikacji. Modyfikacją tą jest wykorzystanie techniki *tampoliny*, polegającej na zwracaniu następnego kroku kontynuacji jako wyniku obecnego kroku zamiast bezpośredniego wywołania dalszej części kontynuacji [[cite:Appel1992]].

Technika ta pozwala przerwać działanie kontynuacji pomiędzy poszczególnymi jej krokami przez zwyczajne nie-wywoływanie następnego kroku, a do jej implementacji wymagana jest jedynie modyfikacja kodu pośredniego programów w miejscach, w których normalnie następowałaby aplikacja następnej części kontynuacji. Listing [[ref:code:ex-cps-execution]] pokazuje efekt zastosowanej modyfikacji algorytmu konwersji CPS oraz wyników uruchomienia poszczególnych kroków kontynuacji.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykład uruchomienia funkcji z listing \ref{code:ex-cps-principle}.}}
#+latex: \label{code:ex-cps-execution}
#+LaTeX: \begin{multicols}{2}
#+begin_src scheme
;; Konwersja wbudowanych funkcji:
(define (__+ a b cont)
  (&yield-cont cont (+ a b)))

;; Przykładowe wyrażenie:
((lambda (x y cont)
   (__+ x y
        (lambda (v)
          (__* 2 v cont))))
 23
 5
 identity)
#+END_SRC
#+LaTeX: \columnbreak
#+BEGIN_SRC scheme
;; Po pierwszym kroku:
(&yield-cont (lambda (v)
               (__* 2 v cont))
             (+ 23 5))

;; Po drugim kroku:
(&yield-cont cont
             (* 2 28))

;; Po trzecim kroku:
56
#+end_src
#+LaTeX: \end{multicols}
#+latex: \end{listing}

Przykład pokazuje, iż jedyną wymaganą modyfikacją jest emitowanie wywołań wbudowanej funkcji =&yield-cont= w miejscach bezpośredniego wywołania następnej kontynuacji. Funkcja =&yield-cont= zwyczajnie zwraca następny krok kontynuacji wraz z wartością, która ma do niego trafić - tak zwaną *dziurą kontynuacji*. W celu kompletnego uruchomienia kontynuacji należy sukcesywnie aplikować zwracaną funkcję do zwracanej wartości.

Wykorzystanie techniki trampoliny prowadzi do powstania /punktów sekwencyjnych/ w programie, czyli miejsc, w których *gwarantowane* jest wykonanie dotychczasowych obliczeń (w szczególności /efektów/ takich jak mutacja wartości). Miejsca te są analogiczne do punktów sekwencyjnych obecnych w interpreterach kodu bajtowego oraz interpreterach redukcyjnych [[cite:PeytonJones1992]], i mogą z powodzeniem służyć do realizowania podobnych funkcji - na przykład /debugowania/, lub /wywłaszczania/. Zostało to opisane w sekcji [[ref:sec:cfs-impl]].

** Implementacja obsługi błędów
Środowisko uruchomieniowe języka =FOOF= pozwala zrealizować obecny w języku zaawansowany mechanizm obsługi błędów i sytuacji wyjątkowych. Mechanizm ten został zaimplementowany w oparciu o kontynuacje i korzysta z dwóch funkcji wbudowanych dostarczanych przez środowisko uruchomieniowe.

Funkcje te, =&uproc-error-handler= oraz =&set-uproc-error-handler!= są odpowiedzialne za zarządzanie aktualnie aktywną procedurą obsługi sytuacji wyjątkowej, a ich wywołania są emitowane w fazie konwersji /Continuation Passing Style/ opisanej szczegółowo w sekcji [[ref:sec:cps-impl]]. Listing [[ref:code:ex-cps-errors]] demonstruje wykorzystanie wymienionych wyżej funkcji w generowanym w fazie konwersji CPS kodzie pośrednim.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie kontynuacji do implementacji obsługi błędów.}}
#+latex: \label{code:ex-cps-errors}
#+BEGIN_SRC scheme
;; Konwersja (raise error):
(let ((__handler (&uproc-error-handler)))
  (__handler __error
             (lambda (__value __ignored)
               (&set-uproc-error-handler! __handler)
               ...
               __value
               ...)))

;; Konwersja (handle expression new-handler):
(let ((__handler (&uproc-error-handler)))
  (&set-uproc-error-handler!
   (lambda (__error __restart)
     (&set-uproc-error-handler! __handler)
     ...
     __new-handler
     ...))
  ...
  __expression
  ...
  (&set-uproc-error-handler! __handler)
  ...)
#+end_src
#+latex: \end{listing}

Powyższy, kryptyczny przykład pokazuje relatywnie skomplikowany kod generowany dla fundamentalnie nieskomplikowanych operacji =raise= oraz =handle= realizujących obsługę błędów w języku =FOOF=. Należy zwrócić uwagę na zastosowanie kontynuacji - procedura obsługi sytuacji wyjątkowej jest zwykłą, reifikowaną do postaci funkcji kontynuacją, której zadaniem jest wywołanie faktycznej funkcji obsługującej zdarzenie. Sygnalizacja zaistnienia błędu polega wtedy na aplikacji tak zbudowanej kontynuacji z sygnalizowaną wartością oraz aktualną kontynuacją, która realizuje restart obliczeń.

Skomplikowanie powyższego kodu wynika z konieczności odpowiedniego zarządzania procedurami obsługi zdarzeń wyjątkowych - musi istnieć gwarancja, że zrestartowane obliczenia zostaną uruchomione z tą samą procedurą obsługi zdarzeń, a po ich zakończeniu zostanie przywrócona poprzednia procedura, natomiast nowodeklarowana procedura obsługi błędu powinna być uruchomiona w kontekście poprzednio zadeklarowanej procedury. Alternatywnym rozwiązaniem, które prowadzi do nieznacznego zredukowania skomplikowania powyższego kodu, jest rozszerzenie bazowego algorytmu konwersji przekazywania kontynuacji w taki sosób, by przekazywane były dwie kontynuacje - pierwsza, będąca włąściwą kontynuacją oraz druga, odpowiedzialna za obsługę sytuacji wyjątkowych [[cite:Appel1992]]. Implementacja tego rozwiązania nie jest dostatecznie opłacalna, powodując nieznaczny narzut szybkości i utrudniając implementację kilku kluczowych optymalizacji, w związku z czym nie została zrealizowana w implementacji języka =FOOF=.

** Implementacja procesów
Jednym z kluczowych elementów języka =FOOF= jest wsparcie dla przetwarzania współbieżnego zrealizowanego za pomocą notacji procesów. Procesy, zwane w nomenklaturze =FOOF= mikroprocesami (w celu rozróżnienia z relatywnie kosztownymi pod względem wykorzystania pamięci i szybkości przełączania procesami systemu operacyjnego) wymagają znacznego wsparcia ze strony środowiska uruchomieniowego języka.

Wsparcie to, w dodatku do uruchamiania procesów (sekcja [[ref:sec:cfs-impl]]), przejawia się organizacją i zarządzaniem ich kontekstami. Kontekstem mikroprocesu jest zbiór globalnych wartości dostępnych i modyfikowanych podczas jego działania przez środowisko uruchomieniowe oraz różne funkcje wbudowane dostępne dla programistów. Schemat [[ref:fig:uproc-processes]] obrazuje organizację obiektu reprezentującego kontekst mikroprocesu.

#+begin_center
#+label: fig:uproc-processes
#+caption: Schemat kontekstu procesu obrazujący rejestry niezbędne do jego działania.
#+attr_latex: :width 0.5\textwidth :placement [H]
[[file:./img/uprocprocesses.pdf]]
#+end_center

Podstawowa wersja kontekstu mikroprocesu wymaga istnienia czterech rejestrów:
- pierwszy z nich, *header*, jednoznacznie identyfikuje obiekt jako kontekst mikroprocesu, dzięki czemu obiekty te mogą być przetwarzane przez programy języka =FOOF=.

- rejestr *status* określa aktualny stan, w którym znajduje się działający proces, jest to jedna z wartości: =running=, =waiting=, =halted= lub =waiting-4-message= oznaczające odpowiednio: działanie, oczekiwanie na uruchomienie, zatrzymanie lub oczekiwanie na wiadomość (opisane w sekcji [[ref:sec:actor-model-impl]]).

- rejest *cont* zawiera aktualnie uruchomianą kontynuacją w formacie trampoliny, czyli funkcję kodującą aktualną kontynuację oraz wartość, która zostanie do niej przekazana. Trampoliny tworzone są za pomocą wbudowanej funkcji =&yield-cont=.

- ostatni rejest, *handler*, reprezentuje aktualnie zadeklarowaną procedurę obsługi zdarzenia wyjątkowego, jest on modyfikowany za pośrednictwem wbudowanych funkcji =&uproc-error-handler= oraz =&set-uproc-error-handler!=.

Rejestry te są podstawowymi rejestrami niezbędnymi do organizacji działania mikroprocesów i są wykorzystywane przez wszystkie zaawansowane funkcjonalności języka. Opis kontekstu mikroprocesów będzie sukcesywnie rozwijany w następnych sekcjach wraz z opisem implementacji poszczególnych funkcjonalności.

** Harmonogramowanie procesów
#+LaTeX: \label{sec:cfs-impl}

Środowisko uruchomieniowe języka =FOOF= zarządza szeregiem struktur danych wykorzystywanych do przechowywania kontekstow mikroprocesów i harmonogramowania (ang. /scheduling/) ich uruchamiania. Do struktur tych należy *lista wszystkich kontekstów* mikroprocesów działających w systemie, wykorzystywana między innymi do pozyskiwania statystyk z działania systemu, oraz *główna kolejka uruchomieniowa*, wykorzystywana w algorytmie harmonogramowania.

Algorytm ten to zmodyfikowana wersja algorytmu /Completely Fair Scheduler/ opisanego szczegółowo w [[cite:Pabla2009]]. Służy on do ustalania kolejności uruchamiania zadań i jest on wykorzystywany w wielu różnych programach, między innymi w jądrze systemu Linux od wersji 2.6.23. Główną cechą algorytmu /CFS/ jest poleganie na *wirtualnych czasach* działania zadań, do których obliczenia wykorzystywany jest ich priorytet i rzeczywisty czas działania, dzięki czemu możliwe jest stosowanie jednej, wspólnej kolejki zadań, zamiast wielu oddzielnych kolejek dla zadań o różnych priorytetach [[cite:Pabla2009]]. Listing [[ref:code:cfs-pseudocode]] prezentuje pseudokod działania algorytmu w notacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Pseudokod zmodyfikowanej wersji algorytmu \textit{Completely Fair Scheduler}.}}
#+latex: \label{code:cfs-pseudocode}
#+BEGIN_SRC scheme
(define (execute-loop)
  (when (not (task-queue-empty?))
    (wait-until-ready)
    (let ((task (dequeue-next-task!)))
      (execute-step task)
      (when (still-running? task)
        (enqueue-task! task))
      (execute-loop))))
#+end_src
#+latex: \end{listing}

Algorytm przebiega w dwóch głównych fazach, które uruchamiane są w pętli tak długo, jak tylko istnieją działające mikroprocesy. Pierwsza faza polega na oczekiwaniu aż jedno z zadań będzie gotowe do uruchomienia (przejdzie ze stanu =waiting= do stanu =running=) a podczas niej środowisko uruchomieniowe może wykonywać inne pożyteczne zadania, takie jak przeprowadzanie automatycznej kolekcji nieużywanej pamięci (ang. /garbage collection/), lub przesyłanie danych do innych, połączonych maszyn. Druga faza korzysta z implementacji kolejki priorytetowej w celu określenia następnego działającego zadania, którego kontynuację następnie uruchamia przez określoną liczbę kroków. W zależności od stanu, w jakim znajduje się zadanie po uruchomieniu jego kontynuacji, jest ono ponownie wstawiane do kolejki priorytetowej po uprzedniej inkrementacji jego rzeczywistego czasu działania.

Priorytety w kolejce mikroprocesów, czyli wirtualne czasy działania zadań, wyznaczane są na podstawie następującej formuły:

#+BEGIN_LaTeX
\begin{equation*}
VirtualTime = RealTime * (MaxPriority - TaskPriority)
\end{equation*}
#+END_LaTeX

#+LaTeX: \noindent
Zapewnia to opisaną powyżej możliwość stosowania jednej struktury danych do harmonogramowania mikroprocesów o różnych priorytetach i gwarantuje, iż mikroprocesy o wyższym priorytecie otrzymają proporcjonalnie większy udział czasu procesora sprzętowego.

Nowo utworzone mikroprocesy, a także te reaktywowane po dłuższym czasie uśpienia, dodawane są do kolejki priorytetowej z rzeczywistym czasem działania odpowiadającym aktualnie najniższemu wirtualnemu czasowi. Technika ta nazywa się *sleeper fairness* i gwarantuje, iż mikroprocesy, które przez dłuższy czas były w stanie uśpienia otrzymają porównywalny do innych mikroprocesów udział czasu procesora po reaktywacji [[cite:Pabla2009]].

Do implementacji powyższego algorytmu niezbędna jest modyfikacja kontekstu mikroprocesów, którą przedstawiono na schemacie [[ref:fig:uproc-cfs]].

#+begin_center
#+label: fig:uproc-cfs
#+caption: Dodatkowe rejestry kontekstu mikroprocesu wymagane do implementacji algorytmu /Completely Fair Scheduler/.
#+attr_latex: :width 0.5\textwidth :placement [H]
[[file:./img/uproccfs.pdf]]
#+end_center

Obiekt kontekstu wzbogacono o dwa rejestry przechowujące odpowiednio priorytet oraz rzeczywisty czas wykonania mikroprocesu. Rejestry te wykorzystywane są przez kolejkę priorytetową, a modyfikowane przez główną pętlę środowiska uruchomieniowego.

Zaimplementowany na potrzeby projektu algorytm został zmodyfikowany w kilku kluczowych miejscach. Pierwszą modyfikacją jest zastosowanie kolejki priorytetowej bazującej na stertach, która charakteryzuje się mniejszą złożonością obliczeniową operacji usuwania minimum niż złożoność, standardowo w tym algorytmie wykorzystywanych, kolejek priorytetowych bazujących na drzewach czerwono-czarnych. Drugą istotną modyfikacją jest brak listy zadań oczekujących, której rolę pełni główna kolejka mikroprocesów - implementacja operacji =sleep= polega na jednorazowej inkrementacji rzeczywistego czasu działania mikroprocesu o zadaną wartość.

** Implementacja Modelu Aktorowego
#+LaTeX: \label{sec:actor-model-impl}

Kolejną integralną częścią wsparcia dla przetwarzania współbieżnego i rozproszonego w środowisku uruchomieniowym języka =FOOF= jest implementacja operacji prymitywnych Modelu Aktorowego opisanych uprzednio w sekcji [[ref:sec:actor-model-description]].

Operacje te w dużej mierze polegają na zarządzaniu kontekstami mikroprocesów oraz modyfikacji ich zawartości, i wymagają dość rozległego wsparcia ze strony środowiska uruchomieniowego. Pierwszą istotną modyfikacją jest konieczność istnienia globalnie dostępnej listy wszystkich działających w systemie mikroprocesów oraz umożliwienie jednoznacznej identyfikacji każdego z nich za pomocą identyfikatorów procesów (ang. /process identifier/, /PID/). System musi także zapewnić łatwy dostęp do kontekstu aktualnie uruchomionego mikroprocesu, w celu umożliwienia implementacji operacji =self=. Drugą modyfikacją jest rozszerzenie kontekstu mikroprocesu o rejestry związane z asynchronicznym przekazywaniem wiadomości. Schemat [[ref:fig:uproc-actor-model]] przezentuje dodatkowe rejestry wymagane przez implementację Modelu Actorowego w języku =FOOF=.

#+begin_center
#+label: fig:uproc-actor-model
#+caption: Rejestry kontekstu mikroprocesu wymagane do implementacji Modelu Aktorowego.
#+attr_latex: :width 0.5\textwidth :placement [H]
[[file:./img/uprocactormodel.pdf]]
#+end_center

Uwzględnienie powyższych modyfikacji pozwala relatywnie łatwo zaimplementować wszystkie opisane w sekcji [[ref:sec:actor-model-description]] operacje prymitywne Modelu Aktorowego:

- Operacja =spawn= polega na stworzeniu nowego kontekstu mikroprocesu,  odpowiednim spreparowaniu jego kontynuacji, priorytetu, procedury obsługi sytuacji wyjątkowych oraz czasu uruchomienia, i dodaniu go do listy aktualnie aktywnych mikroprocesów oraz głównej kolejki uruchomieniowej. Argument przekazany do operacji =spawn=, czyli funkcja realizująca proces, jest /zawijany/ w kontynuację, która zostanie uruchomiona przez algorytm harmonogramowania procesów.

- Operacja =self= polega na zwróceniu wartości rejestru *PID* globalnie dostępnego, aktualnie uruchomionego kontekstu mikroprocesu.

- Operacja =recv=, w zależności od ilości wiadomości znajdujących się aktualnie w kolejce wiadomości aktualnie uruchomionego mikroprocesu (rejestr *MSGq*), robi jedną z dwóch rzeczy: jeśli kolejka wiadomości nie jest pusta, to zostaje zwrócona następna wiadomość w kolejce, jeśli natomiast kolejka jest pusta, to operacja =recv= zmienia stan mikroprocesu (rejestr *status*) na wartość =wait-4-message=, powodując czasowe zatrzymanie uruchamiania procesu. Proces zostanie wznowiony po otrzymaniu następnej wiadomości, która stanie się wynikiem wywołania operacji =recv=.

- Ostatnia operacja, =send=, odpowiada za asynchroniczne przesyłanie wiadomości. Jej głównym zadaniem jest odnalezienie odpowiedniego kontekstu mikroprocesu na podstawie identyfikatora przekazanego w argumentach i dodaniu wiadomości do jego kolejki wiadomości. Jeśli mikroproces będący adresatem wiadomości znajduje się w stanie =wait-4-message=, operacja =send= zmienia ten stan na =running= powodując jego ponowne zakolejkowanie w głównej kolejce uruchomieniowej.

Warto zwrócić uwagę na brak kopiowania wiadomości w implementacji operacji =spawn=. Następuje jedynie skopiowanie referencji wskazującej na blok pamięci zawierający wiadomość, dzięki czemu oba mikroprocesy mają jednakowy dostęp do jego zawartości. Sytuację tę obrazuje schemat [[ref:fig:msg-send]], na którym =μProc0= przekazuje wiadomość o skomplikowanej strukturze do mikroprocesu =μProc1=.

#+begin_center
#+label: fig:msg-send
#+caption: Efekt przekazywania wiadomości pomiędzy mikroprocesami.
#+attr_latex: :width 0.8\textwidth :placement [H]
[[file:./img/msgsend.pdf]]
#+end_center

Brak kopiowania zawartości wiadomości pozwala uniknąć związanego z nim narzutu pamięciowego i degradacji szybkości przesyłania dużej liczby małych wiadomości kosztem konieczności stosowania synchronizacji dostępu do pamięci i pozwalających na dzielenie pamięci algorytmów kolekcji obiektów nieosiągalnych (ang. /garbage collection/). W przeciwieństwie do implementacji analogicznego mechanizmu w języku Erlang stosującego *blokady* (ang. /mutex lock/) [[cite:Armstrong1996]], w implementacji języka =FOOF= zaplanowano wykorzystanie *operacji atomowych* i *barier pamięci* opisanych szczegółowo w [[cite:McKenney2015]].

** Dystrybucja obliczeń
Niestety, ze względu na ograniczenia czasowe narzucone na projekt, nie udało się w pełni zrealizować dystrybucji obliczeń na wiele połączonych ze sobą maszyn. Naturalnie, istnieje możliwość rozszerzenia implementacji środowiska uruchomieniowego języka =FOOF= o wsparcie dla rozproszenia obliczeń.

Wsparcie to wymaga minimalnych modyfikacji środowiska uruchomieniowego polegających na dodaniu do identyfikatorów mikroprocesów fizycznych adresów maszyn, na których są uruchomione, i umożliwieniu komunikacji pomiędzy tymi maszynami. Komunikacja ta może być z powodzeniem zrealizowana w bibliotece standardowej języka =FOOF= przez implementację standardowego interfejsu *gniazd sieciowych BSD* (ang. /BSD sockets/).

Oczywiście, w celu zapewnienia bezpieczeństwa komunikacji pomiędzy maszynami, wymagane będzie zaprojektowanie i wprowadzenie protokołu komunikacji uwzględniającego autoryzację poszczególnych węzłów oraz kontrolę dostępu do ich zasobów [[cite:Tanenbaum2006]]. Problem bezpieczeństwa systemów rozproszonych jest problemem skomplikowanym, a jego rozwiązanie wymaga ostrożnego i długiego planowania.

* Inżynieria wiedzy w języku
#+LaTeX: \label{sec:knowledge-engineering}

Mechanizmy niezbędne do umożliwienia przetwarzania wiedzy w języku =FOOF= stanowią znaczną część jego środowiska uruchomieniowego, w związku z czym opis ich implementacji został wydzielony do niniejszego rozdziału. Niezależnie od tej separacji, opisane w dalszej części rozdziału algorytmy i struktury danych stanowią integralną część środowiska uruchomieniowego, które nie byłoby bez nich kompletnie funkcjonalne.

Głównym zadaniem inżynierii wiedzy w implementacji języka =FOOF= jest osiągnięcie opisanej w sekcji [[ref:sec:thesis-motivation]] *świadomości platformy*, czyli umożliwieniu refleksji na temat platformy sprzętowej, na której działa system rozproszony, a także struktury samego systemu. Refleksja taka umożliwia podejmowanie decyzji podczas działania aplikacji i prowadzi do lepszego wykorzystania zasobów maszyny i reagowania na zmiany zachodzące w systemie. Listing [[ref:code:heterogeneity-solved-pseudocode]] prezentuje pseudokod w notacji języka =FOOF= obrazujący wykorzystanie wiedzy do rozwiązania problemu hoterogeniczności.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie inżynierii wiedzy do rozwiązania problemu heterogeniczności.}}
#+latex: \label{code:heterogeneity-solved-pseudocode}
#+BEGIN_SRC scheme
(define (transmogrify loads-of-data)
  (let ((nodes (find-all (and (node ?node)
                              (has ?node superscalar-hardware)
                              (has ?node do-transmogrify))))))
  (if (not (empty? nodes))
      (pmap (lambda (n data)
              (rpc n do-transmogrify data))
            nodes
            (chunkify loads-of-data (length nodes)))
      (pmap do-transmogrify
            (chunkify loads-of-data 10))))

(define (do-transmogrify data)
  ;; Kosztowne obliczenia...
  )
#+end_src
#+latex: \end{listing}

Przykład definiuje funkcję =transmogrify=, której zadaniem jest wykonanie kosztownych obliczeń na dużym zbiorze danych. Funkcja ta odpytuje bazę wiedzy dostępną w języku o istnienie podłączonych maszyn wyposażonych w procesory superskalarne i potrafiących wykonać operację /transmogryfikacji/ za pomocą operacji =find-all=. Następnie, w zależności od wyniku zapytania, dzieli dane na porcje, które albo przekazuje do owych, superskalarnych maszyn za pomocą zdalnego wywołania funkcji (ang. /remote procedure call/), albo przetwarza lokalnie za pomocą ustalonej liczby współbieżnie działających procesów. Wykorzystanie bazy wiedzy pozwala w łatwy sposób reagować na podłączenie dodatkowych superskalanych maszyn - funkcja zwyczajnie zacznie z nich korzystać. Można sobie także wyobrazić sytuację, w której system dysponuje wiedzą o szybkości działania implementacji funkcji =transmogrify= na różnych połączonych maszynach i wybiera najszybszą z nich już w miejscu jej wywołania.

Sekcja [[ref:sec:knowledge-engineering-description]] wprowadza podstawowe definicje i pojęcia dotyczące reprezentacji i przetwarzania wiedzy, które będą wykorzystywane w niniejszym rozdziale. Konkluzją tej sekcji jest konieczność wykorzystania *systemu regułowego* w celu osiągnięcia pożądanej funkcjonalności.

** Reprezentacja wiedzy w języku
Wiedza w języku =FOOF= reprezentowana jest przez *fakty* i *reguły*, które przechowywane są w osobnych bazach danych. Bazy te zaimplementowane zostały jako zwykłe, liniowe przestrzenie N-krotek (ang. /tuple spaces/) - trójek =(identyfikator, wzorzec, akcja)= w przypadku reguł i jedno-krotek zawierających pewną wartość w przypadku faktów. Obie bazy wspierają szereg operacji, które schematycznie zaprezentowano na rysunku [[ref:fig:fact-rule-store]].

#+begin_center
#+label: fig:fact-rule-store
#+caption: Schemat działania wbudowanych baz faktów i reguł.
#+attr_latex: :width 0.9\textwidth :placement [H]
[[file:./img/factrulestore.pdf]]
#+end_center

Fakty kodowane są przez wbudowane w język =FOOF= typy danych i mogą być dowolnie skomplikowane. Jedynym ograniczeniem narzucanym przez implementację jest acykliczność faktów w celu ułatwienia ich porównywania i dopasowywania do wzorców. Reprezentacja ta jest znacznie bardziej liberalna, niż reprezentacja wiedzy w systemach ontologicznych, gdzie fakty ograniczone są do trójek =(obiekt, właściwość, wartość)= [[cite:Wang2013, Hachem2011]]. Listing [[ref:code:facts-example]] prezentuje przykłady faktów w notacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykładowe fakty w notacji języka \texttt{FOOF}.}}
#+latex: \label{code:facts-example}
#+BEGIN_SRC clojure
42.7
'fakt
'(ustrukturyzowany fakt)
'[fakty nie są ograniczone do trójek]
'{:typ struktura :ograniczona? nie}
#+end_src
#+latex: \end{listing}

Dodawanie faktów do bazy faktów przebiega z wykorzystaniem funkcji =assert!= i jest nazywane asercją, lub stwierdzeniem faktu. Odwrotną operacją jest retrakcja, lub cofnięcie faktu, osiągane za pomocą funkcji =retract!=. Retrakcja polega na *strukturalnej identyczności*, nie na identyczności referencji, w związku z czym jest operacją dość kosztowną obliczeniowo. Dodatkowo, implementacja przewiduje istnienie operacji =signal!=, która konceptualnie polega na asercji i następnie retrakcji faktu. Operacja ta została zoptymalizowana w taki sposób, by wyzwolić efekty asercji faktu bez modyfikacji żadnych struktur danych.

Reguły deklarowane są za pomocą wbudowanej funkcji =whenever= i składają się z dwóch elementów: *wzorca* wiążącego struktury faktów oraz *akcji*, które mają zostać wykonane w przypadku dopasowania wzorca do pewnego podzbioru stwierdzonych faktów. Listing [[ref:code:rules-example]] pokazuje przykłady reguł w notacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykładowe fakty w notacji języka \texttt{FOOF}.}}
#+latex: \label{code:rules-example}
#+BEGIN_SRC scheme
(whenever wzorzec akcja ...)

(whenever '(and (country ?country)
                (coughing a-man ?country))
  (shut-down-madagascar))
#+end_src
#+latex: \end{listing}

W związku z dowolnością reprezentacji faktów, wzorce reguł również mogą być dowolnie skomplikowane. Dodatkowo, język =FOOF= udostępnia specjalny język domenowy służący do definiowania wzorców reguł, w którym symbole prefixowane przez znak zapytania oznaczają zmienne logiczne (=?country= w przykładzie). Poszczególne konstrukcje języka definicji wzorców zostały opisane w sekcji [[ref:sec:rete-impl]] przy okazji opisu implementacji systemu regułowego.

Operacje prymitywne bazy reguł to: dodawanie reguły za pomocą funkcji =whenever= oraz usuwanie reguły za pomocą funkcji =remove-rule!=. Implementacja korzysta z logicznego usuwania reguł - akcje związane z regułą nie są uruchamiane, ale reguła nadal jest obecna w strukturach danych implementacji systemu regułowego. Dodatkowo, zaimplementowana została funkcja =select=, która pozwala uruchomić regułę bez dodawania jej do bazy reguł.

** Algorytm Rete
#+LaTeX: \label{sec:rete-impl}

Najłatwiejszą implementacją powyższego interfejsu jest podejście naiwne polegające na iteracyjnym aplikowaniu każdego faktu do każdego wzorca reguły. Rozwiązanie to, mimo że jest proste w implementacji, jest również bardzo niewydajne - jego złożoność obliczeniowa jest rzędu *O(RF^P)*, dla =R= reguł, =F= faktów i =P= średniej ilości /elementarnych podwzorców/ przypadających na lewą stronę reguły.

Standardowym rozwiązaniem wykorzystywanym w implementacjach systemów regułowych, które jednocześnie posiada dużo lepszą złożoność obliczeniową, jest, zaprojektowany w 1974 roku i rozwinięty w roku 1979 przez Charls'a Forgy'iego, algorytm *Rete* [[cite:Forgy1979]]. Jego złożoność obliczeniowa jest rzędu *O(RFP)*, co prowadzi do znacznego zwiększenia szybkości działania systemu regułowego względem naiwnej implementacji, kosztem zauważalnego zwiększenia wykorzystania pamięci [[cite:Forgy1982]]. Algorytm ten jest relatywnie nieskomplikowany i jednocześnie zadowalająco wydajny, w związku z czym został wykorzystany w implementacji języka =FOOF=.


Algorytm Rete (w tłumaczeniu z języka włoskiego /sieć/) polega na automatycznej budowie sieci węzłów różnych rodzajów na podstawie wzorca reguły. Węzły te odpowiadają za podstawowe operacje, takie jak dopasowywanie strukturalne faktów (ang. /pattern matching/), unifikację faktów (ang. /unification/) oraz uruchamianie akcji, i dzielą się na dwie klasy:

- węzły *alfa* przyjmujące jedną wartość, których zadaniem jest dyskryminacja wartości na podstawie ich struktury oraz typu,

- węzły *beta* przyjmujące dwie wartości, których zadaniem jest unifikacja tych wartości w celu weryfikacji spójności informacji, które ze sobą niosą.

Podczas działania algorytmu, węzły mogą zadecydować, na podstawie wewnętrznych zasad działania, czy przekazaną do nich wartość (fakt) mogą przekazać do następnych węzłów. W tym celu, obie opisane klasy węzłów algorytmu Rete korzystają z pamięci do przechowywania dotychczasowo napotkanych faktów. W przypadku węzłów alfa jest to prosta lista faktów, która pozwala je zapamiętać w celu późniejszego odrzucenia duplikatów - realizuje asercję faktu. Węzły beta używają dwóch oddzielnych pamięci faktów lewo- oraz prawo-stronnych odpowiednio dla /lewego/ i /prawego/ przyjmowanego argumentu. Podział pamięci węzłów beta pozwala unifikować nowe wartości ze wszystkimi dotychczasowo zapisanymi wartościami pochodzącymi z drugiego argumentu, co stanowi podstawę działania algorytmu Rete i jego wysokiej wydajności [[cite:Forgy1982]].

Wspomniana powyżej *unifikacja* polega na przypisaniu, obecnych we wzorcach reguł, zmiennych logicznych do odpowiadających im elementów struktury faktu. Unifikacja zapewnia także wymuszenie spójności tak przypisanych wartości pochodzących z dwóch różnych części sieci Rete - algorytm dba o to, by wartości tych samych zmiennych logicznych były równe. Listing [[ref:code:unification-example]] pokazuje kilka przykładów działania unifikacji wykorzystanej w implementacji środowiska uruchomieniowego języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykłady działania algorytmu unifikacji w notacji języka \texttt{FOOF}.}}
#+latex: \label{code:unification-example}
#+BEGIN_SRC clojure
(unify '(some ?pattern) '(some fact))       ;; {?pattern fact}
(unify '(another ?pattern) '(some fact))    ;; Unifikacja nieudana.
(unify '{?pattern some} '{?pattern noster}) ;; Unifikacja nieudana.
(unify '{?a a ?b 23} '{?b 23 ?c 5})         ;; {?a a ?b 23 ?c 5}
#+end_src
#+latex: \end{listing}

Implementacja algorytmu Rete w języku =FOOF= dostarcza następujące, podstawowe typy węzłów:

- Węzły *node-1*, odpowiadające węzłom klasy alfa, to proste węzły przeprowadzające dopasowanie strukturalne faktów i elementarnych wzorców reguł, na przykład =(some ?pattern)=. Wynikiem ich działania jest mapowanie nazw zmiennych logicznych na odpowiadające im wartości.

- Węzły *node-2*, odpowiadające węzłom klasy beta, to węzły unifikujące wartości zmiennych logicznych pochodzących z dwóch źródeł. Wynikiem ich działania jest lista map reprezentujących zunifikowane fakty pasujące do obu gałęzi sieci prowadzących do obecnego węzła. Węzły te tworzone są za pomocą konstrukcji =(and podwzorzec-1 podwzorzec-2 ...)=.

- Węzły *node-a*, czyli węzły uruchamiające akcje zadeklarowane po prawej stronie reguły.

Dodatkowo, implementacja została rozszerzona o następujące typy węzłów, realizujące wiele przydatnych funkcji:

- Węzły *node-p*, czyli węzły predykatów umożliwiające nietrywialną filtrację faktów, na przykład =(filter podwzorzec predykat-1 predykat-2 ...)=.

- Węzły *node-r* przechowujące dodatkowy stan, pozwalające na akumulację (lub w ogólnym przypadku /redukcję/) zmieniających się wartości faktów na podstawie odrębnych zasad. Węzły te deklarowane są za pomocą konstrukcji =(reduce akumulator podwzorzec)=.

- Węzły *node-t*, czyli węzły wyzwalane, pozwalające na obserwowanie trendu zmiany wartości faktów dzięki buforowi wartości faktów i osobnemu predykatowi. Węzły te są tworzone przez konstrukcję =(trigger bufor podwzorzec predykat)=.

Implementacja powyższych węzłów przewiduje możliwość dodania optymalizacji struktury sieci, która w chwili obecnej nie jest stosowana. Optymalizacja ta polega na łączeniu identycznych fragmentów sieci Rete, co prowadzi do dodatkowej redukcji ilości wykonywanych operacji oraz wykorzystywanej przez sieć pamięci, a także zwiększenia wydajności całego algorytmu. Schemat [[ref:fig:rete-network-merge]] prezentuje działanie tej optymalizacji.

#+begin_center
#+label: fig:rete-network-merge
#+caption: Schemat łączenia podsieci w algorytmie /Rete/.
#+attr_latex: :width 1.0\textwidth :placement [H]
[[file:./img/retemerge.pdf]]
#+end_center

Przykład pokazuje łączenie podsieci dwóch oddzielnych reguł, które charakteryzują się podobną strukturą. Wynikiem działania optymalizacji jest semantycznie identycznie funkcjonująca sieć, która jednocześnie działa znacznie szybciej dzięki redukcji duplikacji przetwarzania informacji.

Naturalnie, istnieje wiele innych usprawnień algorytmu Rete, także autorstwa Charls'a Forgy'iego, które poprawiają jego wydajność i stabilność działania. Najciekawsze z nich dotyczą możliwości parallelizacji przetwarzania wiedzy [[cite:Gupta1986]] oraz wykorzystania specjalnych przypadków oryginalnego algorytmu Rete [[cite:Miranker1987]]. Usprawnienia związane ze współbieżnym przetwarzaniem wiedzy zostały szczegółowo przeanalizowane w sekcji [[ref:sec:rete-integration]].

** Implementacja wnioskowania w przód
Głównym zadaniem algorytmu Rete w implementacji języka =FOOF= jest umożliwienie *wnioskowania*, czyli odkrywania nowej, uprzednio nieznanej wiedzy na podstawie wcześniej stwierdzonych faktów. Istnieją dwa główne sposoby prowadzenia wnioskowania: *w przód* poruszony w niniejszej sekcji oraz *wstecz*, który został opisany w sekcji [[ref:sec:backwards-chaining-impl]].

Wnioskowanie w przód polega na wyjściu od posiadanej wiedzy i aplikowaniu zasad inferencji tak długo, aż osiągnięte zostaną pewne cele. Konceptualnie jest to jednoznaczne z równoległą eksploracją wszystkich możliwych ścieżek inferencji wraz z napływem nowych danych i stopniowym osiąganiem postawionych celów. Ten typ wnioskowania jest szczególnie skuteczny w dynamicznych zastosowaniach, gdzie baza wiedzy ulega ciągłym zmianom a zestaw celów jest potencjalnie bardzo duży, takich jak Systemy Ekspertowe i Systemy Regułowe.

Wnioskowanie w przód jest standardowym trybem pracy algorytmu Rete, w związku z czym jego implementacja jest trywialna i polega jedynie na umożliwieniu tworzenia reguł i asercji nowych faktów. W kontekście implementacji języka =FOOF= celami są akcje zdefiniowane w regułach, natomiast wnioskowanie polega na ciągłej aktualizacji sieci Rete wartościami napływających faktów.

** Implementacja wnioskowania wstecz
#+LaTeX: \label{sec:backwards-chaining-impl}

Przeciwieństwem wnioskowania w przód jest wnioskowanie wstecz. Polega ono na wyjściu od pożądanego celu i próbie uproszczenia go, poprzez stosowanie zasad inferencji, do podstawowych aksjomatów, by udowodnić jego osiągalność. Konceptualnie odpowiada to zadaniu konkretnego zapytania bazie wiedzy w celu otrzymania jednoznacznej odpowiedzi, gdzie zapytanie jest celem wnioskowania, a zadaniem bazy wiedzy jest zweryfikowanie jego osiągalności.

Realizacja wnioskowania wstecz w środowisku uruchomieniowym języka =FOOF= polega na implementacji algorytmu Rete oraz istnieniu wbudowanej bazy faktów. W celu przeprowadzenia wnioskowania wstecz, środowisko uruchomieniowe tworzy nową sieć Rete, której nie dodaje do globalnej bazy reguł, po czym iteracyjnie aplikuje do niej wszystkie znane fakty znajdujące się w bazie faktów, akumulując rezultaty inferencji. Wynikiem działania wnioskowania wstecz jest lista wszystkich mapowań zmiennych logicznych do wartości, które spełniają zapytanie. Listing [[ref:code:backwards-chaining-example]] prezentuje zastosowanie konstrukcji =select= służącej do tworzenia zapytań do bazy faktów dostępnej w języku.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Przykłady wykorzystania wnioskowania wstecz w języku \texttt{FOOF}.}}
#+latex: \label{code:backwards-chaining-example}
#+BEGIN_SRC clojure
;; Lista wszystkich faktów obecnych w bazie faktów:
(select '?any)

;; Lista wszystkich dostępnych modułów:
(select '(module ?m))

;; Lista wszystkich modułów dostarczających funkcję transmogrify:
(select '(and (module ?m)
              (provides ?m transmogrify)))
#+end_src
#+latex: \end{listing}

Pierwszy z przykładów powoduje zwrócenie listy wszystkich faktów obecnych w bazie faktów. Drugi przykład ogranicza tę listę do nazw modułów języka =FOOF=, które są dostępne w aplikacji, natomiast ostatni dodatkowo ogranicza listę dostępnych modułów do tych, które definiują funkcję =transmogrify=. Przykłady te pokazują, iż wnioskowanie wstecz szczególnie dobrze nadaje się do zastosowań, gdzie baza wiedzy jest statyczna.

Warto zauważyć, iż opisana powyżej implementacja jedynie /emuluje/ wnioskowanie wstecz w rzeczywistości przeprowadzając wnioskowanie w przód dla jednej tylko reguły. Liniowa w stosunku do ilości faktów złożoność obliczeniowa tego rozwiązania jest adekwatna, ale w przyszłości istnieje możliwość implementacji osobnego mechanizmu opartego o *przeszukiwanie w głąb*. Wadą obecnej implementacji jest konieczność istnienia osobnej bazy faktów, która musi być pozostawać w ciągłej synchronizacji ze stanem globalnej sieci Rete znajdującej się w bazie reguł.

** Integracja ze Środowiskiem Uruchomieniowym
#+LaTeX: \label{sec:rete-integration}

Obecna implementacja systemu regułowego nie jest całkowicie zintegrowana z pozostałą częścią środowiska uruchomieniowego języka =FOOF=. Została ona zrealizowana jako szereg wbudowanych funkcji, w związku z czym posiada wiele technicznych ograniczeń.

Pierwszym i zarazem największym ograniczeniem, jest utrudnienie realizacji operacji =whenever=, której zadaniem jest dodawanie nowych reguł. Operacja ta jako argumenty przyjmuje wzorzec stanowiący lewą stronę reguły, oraz funkcję, która reprezentuje prawą stronę reguły. Organiczenie polega na tym, iż funkcja reprezentująca prawą stronę reguły wymaga przekazania /aktualnej kontynuacji/ podczas wywołania. Kontynuacja ta, z racji asynchroniczności systemu regułowego nie istnieje po stworzeniu reguły, w związku z czym nie może zostać przekazana do wywoływanej funkcji. Listing [[ref:code:rete-fuckup-solved]] prezentuje alternatyną implementacją operacji =whenever=, która została zrealizowana w implementacji języka =FOOF=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Alternatywna implementacja operacji \texttt{whenever}.}}
#+latex: \label{code:backwards-chaining-example}
#+BEGIN_SRC clojure
(notify-whenever identyfikator wzorzec)
(notify-whenever (self) '(temperature ?t))
#+end_src
#+latex: \end{listing}

Wprowadzona konstrukcja =notify-whenever= zamiast funkcji reprezentującej akcję przyjmuje identyfikator procesu, który zostanie asynchronicznie poinformowany o spełnieniu reguły zadanej podanym wzorcem.

Drugą limitacją zaimplementowanego systemu regułowego jest /logiczne/ usuwanie reguł z odpowiednie bazy danych, polegające na wyłączeniu efektów związanych z regułą akcji. Usunięta w ten sposób reguła nadal jest przetwarzana podczas wnioskowania, a jedynie efekty jej działania są pomijane.

Kolejnym ograniczeniem, jest fakt istnienia globalnych baz danych zawierających fakty i reguły. Dane te stanowią *stan* aplikacji, którego istnienie nie jest pożądane w funkcyjnych językach programowania, do których należy język =FOOF= [[cite:Backus1978]]. Rozwiązanie tego problemu (zaprezentowane na schemacie [[ref:fig:distributed-rete]]) wymaga znaczących zmian architekturalnych w środowisku uruchomieniowym, w zamian pozwalając na implementację szeregu ciekawych optymalizacji.

#+begin_center
#+label: fig:distributed-rete
#+caption: Schemat działania współbieżnej wersji algorytmu /Rete/.
#+attr_latex: :width 0.6\textwidth :placement [H]
[[file:./img/distributedrete.pdf]]
#+end_center

Rozwiązanie to polega na zrównolegleniu przetwarzania wiedzy w języku =FOOF= - każda reguła reprezentowana jest przez osobny mikroproces, którego jedynym zadaniem jest oczekiwanie na nowe fakty oraz notyfikacja procesów-właścicieli w przypadku spełnienia reguły. Regułami zarządza jeden proces pośredniczący w komunikacji, który jednocześnie zarządza bazą faktów eliminując problem jej synchronizacji ze stanem sieci Rete.

Architektura ta pozwala na konkurencyjne istnienie wielu procesów pośredniczących, a co za tym idzie, wielu baz faktów i wielu odseparowanych sieci Rete, pozwalając na implementację systemów regułowych dedykowanych dla części aplikacji. Dodatkowo, do zalet tego rozwiązania należą: zwiększenie bezpieczeństwa i odporności systemu regułowego przez separację poszczególnych jego elementów, możliwość łatwego zrealizowania fizycznego usuwania reguł, a także możliwość przeniesienia całości implementacji do biblioteki standardowej języka =FOOF=. Opisana architektura stanowi dobrą alternatywę dla zrównoleglonej wersji algorytmu Rete przedstawionej w [[cite:Gupta1986]].

* Podsumowanie
#+latex: \label{sec:outro}

Celem pracy było zaprojektowanie i zaimplementowanie języka programowania wspierającego przetwarzanie współbieżne i rozproszone na platformach heterogenicznych. W tym celu stworzono pragmatyczny, funkcyjny język programowania ogólnego przeznaczenia, roboczno nazwany =FOOF=, kompilator jego kodu źródłowego oraz środowisko uruchomieniowe rozwiązujące problem heterogeniczności z wykorzystaniem inżynierii wiedzy.

Postawiony cel został osiągnięty, a powstały język programowania jest funkcjonalny i stanowi ciekawe, eksperymentalne narzędzie służące do eksploracji ideologii *świadomości platformy* (ang. /platform awareness/). Ideologia ta polega na uniezależnieniu od platformy poprzez wykorzystanie wiedzy i stanowi alternatywę dla niezależności od platformy (ang. /platform independence/) głoszonej przez większość popularnych języków programowania, która w rzeczywistości polega na zignorowaniu i homogenizacji platformy sprzętowej.

Naturalnie, ze względu na rozmiar i ograniczenia czasowe nałożone na projekt, nie udało się uniknąć pewnych niedogodności, a sama tematyka nie została wyczerpana w stu procentach, zostawiając szerokie pole do przyszłego rozwoju, co opisano w następnych sekcjach.

** Problemy kompilatora języka =FOOF=
Implementacja kompilatora języka =FOOF= w chwili obecnej nie posiada fazy optymalizacji, w związku z czym emitowany kod jest mało wydajny. Dodatkowo, faza generacji kodu nie emituje kodu maszynowego, co potęguje efekt.

Kolejnym problemem jest obsługa błędnego kodu źródłowego, która jest bardzo ograniczona. Kompilator spodziewa się dobrze uformowanego, prawidłowego kodu wejściowego i nie stara się wykrywać jego błędów, co w przypadku dostarczenia nieprawidłowego kodu źródłowego może skończyć się błędem i przedwczesnym zakończeniem działania kompilatora.

** Problemy Środowiska Uruchomieniowego
Środowisko uruchomieniowe języka =FOOF= nie jest kompletne, nie obsługuje części wbudowanych typów danych, takich jak mapy i wektory. Polega ono w dużej mierze na środowisku uruchomieniowym języka Scheme, co utrudni w przyszłości realizację kompilacji do kodu maszynowego.

Wsparcie dla przetwarzania rozproszonego jest obecnie szczątkowe i polega na wbudowanych w język Scheme procedurach komunikacji sieciowej. Środowisko uruchomieniowe języka =FOOF= nie udostępnia mechanizmów kontroli dostępu do zasobów oraz komunikacji pomiędzy maszynami.

Kolejnym problemem środowiska uruchomieniowego jest połowiczne wsparcie dla niektórych zaawansowanych funkcjonalności języka, takich jak makra i wbudowany system regułowy. W przypadku systemu makr, użytkownik nie ma możliwości zdefiniowania nowych makr i musi polegać jedynie na tych wbudowanych w środowisko uruchomieniowe.

Problemy wbudowanego systemu regułowego wynikają natomiast z niewłaściwego doboru architektury i zostały szczegółowo opisane w sekcji [[ref:sec:rete-integration]]. Proponowane rozwiązanie wymaga znaczących zmian architekturalnych środowiska uruchomieniowego języka =FOOF=.

** Przyszłe kierunki rozwoju
Projekt będący częścią niniejszej pracy jest daleki od bycia kompletnym. W związku z koniecznością rozwiązania opisanych powyżej niedogodności zidentyfikowano następujące kierunki przyszłego rozwoju:

- Implementacja większej liczby typów danych, w szczególności map oraz wektorów i związanych z nimi elementarnych operacji, celem wsparcia wielu zależnych od nich technik programistycznych.

- Wraz z implementacją wektorów istnieje możliwość zrównoleglenia podstawowych operacji na wektorach na poziomie dostępu do danych (ang. /data-level parallelism/), co pozwoli osiągnąć znaczne przyspieszenie programów przetwarzających duże zbiory danych.

- Umożliwienie kompilacji do kodu maszynowego, na przykład za pomocą infrastruktury GCC (ang. /GNU Compiler Collection/) lub LLVM (ang. /Low-Level Virtual Machine/). Kierunek ten zapewni największe korzyści dla ekosystemu języka programowania =FOOF=.

- Rozwinięcie środowiska uruchomieniowego języka, w celu polepszenia wsparcia kluczowych funkcjonalności języka, takich jak wsparcie dla przetwarzania rozproszonego, lub obsługa makr użytkownika. Rozwój ten jest niezbędny do osiągnięcia pełnej funkcjonalności języka.

- Przeniesienie implementacji wbudowanego systemu regułowego do biblioteki standardowej języka =FOOF= oraz usprawnienie jego działania. Zabieg ten pozwoli znacząco zredukować skomplikowanie projektu i ułatwi realizację pozostałych kierunków rozwoju.

#+LaTeX: \noindent
Wszystkie wymienione kierunki rozwoju będą w przyszłości aktywnie eksplorowane.

# The bibliography
#+begin_latex
\bibliographystyle{ieeetr}
\bibliography{bibs}
#+end_latex

#+latex: \appendix
* Gramatyka języka =FOOF=
#+LaTeX: \label{sec:foof-grammar}

Język =FOOF= jest dialektem języka Lisp, w związku z czym charakteryzuje się bardzo prostą i ujednoliconą składnią bazującą na *S-wyrażeniach*. Listing [[ref:code:foof-grammar]] prezentuje formalną specyfikację składni jęzka w notacji *BNF* (ang. /Bacus-Naur Form/).

#+latex: \begin{listing}[ht]
#+latex: \caption{\mylisting{Gramatyka języka \textt{FOOF}.}}
#+latex: \label{code:foof-grammar}
#+begin_src xml
  <program>        ::= <structure> | <module> | <definitions>
  <structure>      ::= '(' 'structure' <symbol> <definitions> ')'
  <module>         ::= '(' 'module' <symbol-list> <definitions> ')'
  <definitions>    ::= <definition> <definitions> | ''
  <definition>     ::= '(' 'define' <symbol-list> <expression> ')'
                     | '(' 'define' <symbol> <expression> ')'
  <symbol-list>    ::= '(' <symbol> <symbols> ')'
  <symbols>        ::= <symbol> <symbols> | ''
  <expressions>    ::= <expression> <exrpessions> | ''
  <expression>     ::= <value> | <application> | <syntax-form>
  <value>          ::= <atom> | <list> | <vector> | <map>
  <atom>           ::= <string> | <symbol> | <keyword> | <number>
  <application>    ::= '(' <expression> <expressions> ')'
  <syntax-form>    ::= '(' <operator> <expressions> ')' | ''' <expression>
                     | '`' <expression> | ',' <expression>
  <operator>       ::= 'quasiquote' | 'unquote' | 'unquote-splicing'
                     | 'lambda' | 'structure' | 'module' | 'define' | 'let'
                     | 'let*' | 'letrec' | 'letcc' | 'shift' | 'reset'
                     | 'or | 'and' | 'cond' | 'when' | 'unless' | 'if'
                     | 'do' | 'handle' | 'raise' | 'quote'
  <list>           ::= '(' <expressions> ')'
  <vector>         ::= '[' <expressions> ']'
  <map>            ::= '{' <key-values> '}'
  <key-values>     ::= <expression> <expression> <key-values> | ''
  <keyword>        ::= ':' <symbol>
  <symbol>         ::= "Dowolny literał znakowy bez znaków białych."
  <string>         ::= '"' "Dowolny literał znakowy." '"'
  <number>         ::= "Dowolny literał liczbowy."
#+end_src
#+latex: \end{listing}

* Przykładowe programy
#+LaTeX: \label{sec:foof-examples}
Poniżej zaprezentowano przykładowe programy w języku =FOOF= i krótki opis ich działania. Programy mogą zostać skompilowane i uruchomione za pomocą udostępnionego interfejsu kompilatora i środowiska uruchomieniowego języka. W konsoli systemu należy w tym celu wywołać odpowiednio funkcje =compile= i =run= podając interesujący program jako parametr, na przykład:

#+BEGIN_EXAMPLE
> (compile 'program)
> (run 'program)
#+END_EXAMPLE

** Hello world!
Program definuje funkcję =hello= obrazującą podstawowe operacje języka i następnie wywołuje ją z jednym parametrem. Po uruchomieniu program powoduje wypisanie wiadomości =Hello world!= na ekranie komputera.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Popularny program \textit{Hello world!}.}}
#+latex: \label{code:ex-hello-world}
#+begin_src scheme
(define (hello world)
  (if (= nil world)
      (raise 'nope)
      (do (display "Hello ")
          (display world)
          (display "!")
          (newline))))

(hello "world")
#+end_src
#+latex: \end{listing}

** Funkcja Fibonacciego
Program prezentuje definicję funkcji Fibonacciego z wykorzystaniem konstrukcji =letrec=, służącej do definiowania funkcji rekursywnych. Następnie program oblicza wynik funkcji Fibonacciego dla liczby 23.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Definicja funkcji Fibonacciego.}}
#+latex: \label{code:ex-fibonacci}
#+begin_src scheme
(letrec ((fib (lambda (n)
                (if (< n 2)
                    n
                    (+ (fib (- n 1))
                       (fib (- n 2)))))))
  (fib 23))
#+end_src
#+latex: \end{listing}

** Obsługa błędów
Program prezentuje wykorzystanie wbudowanego w język systemu obsługi błędów. Deklarowana jest procedura obsługi błędów, która restartuje obliczenia z nową wartością. Następnie program dwukrotnie sygnalizuje wystąpienie błędu. Wynikiem działania programu jest liczba 24.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Zastosowanie wbudowanego mechanizmu obsługi błędów.}}
#+latex: \label{code:ex-error-handling}
#+begin_src scheme
(* 2 (handle (raise (raise 3))
             (lambda (e restart)
               (restart (* 2 e)))))
#+end_src
#+latex: \end{listing}

** Model Aktorowy
Program korzysta z dwóch komunikujących się procesów do zobrazowania sposobu wykorzystania zaimplementowanego w języku Modelu Aktorowego. Efektem działania programu jest wypisanie wiadomości =Hello world!= na ekranie komputera.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie prymitywnych operacji Modelu Aktorowego.}}
#+latex: \label{code:ex-actor-model}
#+begin_src scheme
(let ((pid (spawn (lambda ()
                    (let ((msg (recv)))
                      (display (cdr msg))
                      (newline)
                      (send (car msg) " world!"))))))
  (send pid (cons (self) "Hello"))
  (display (recv))
  (newline))
#+end_src
#+latex: \end{listing}

** Współbieżne obliczenia funkcji Fibonacciego
Program definiuje funkcję Fibonacciego oraz dodatkową funkcję wyświetlającą informacje o systemie. Następnie tworzone są trzy procesy współbieżnie obliczające wartość funkcji Fibonacciego dla liczby 30. Program periodycznie wyświetla różne informacje o działających procesach.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Równoległe obliczanie funkcji Fibonacciego.}}
#+latex: \label{code:ex-parallel-fibonacci}
#+begin_src scheme
(letrec ((fib (lambda (n)
                (if (< n 2)
                    n
                    (+ (fib (- n 1))
                       (fib (- n 2))))))
         (monitor (lambda ()
                    (task-info)
                    (sleep 2000)
                    (monitor))))
  (spawn (lambda ()
           (fib 30)))
  (spawn (lambda ()
           (fib 30)))
  (spawn (lambda ()
           (fib 30)))
  (monitor))
#+end_src
#+latex: \end{listing}

** System modułowy
Program definiuje dwa moduły - =logger= oraz =test=. Moduł =test= wymaga do działania implementacji modułu logowania. Program tworzy instancję modułu =logger= i następnie tworzy instancję modułu =test= wykorzystując uprzednio zdefiniowany moduł logowania. Efektem działania programu jest wypisanie dwóch wiadomości na ekranie komputera. Wiadomości są odpowiednio sformatowane przez moduł =logger=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie wbudowanego systemu modułowego.}}
#+latex: \label{code:ex-module-system}
#+begin_src scheme
(module (logger)
  (define (log level string)
    (display "[")
    (display level)
    (display "] ")
    (display string)
    (newline))

  (define (debug string)
    (log 'DEBUG string))

  (define (info string)
    (log 'INFO string))

  (define (warn string)
    (log 'WARN string))

  (define (error string)
    (log 'ERROR string)))

(module (test logger)
  (define (do-something)
    (logger.info "doing something")
    (logger.error "failed badly!")))

(let ((t (test (logger))))
  (t.do-something))
#+end_src
#+latex: \end{listing}

** Wnioskowanie w przód
Program prezentuje wykorzystanie wbudowanego w język systemu regułowego. Definiowane są trzy funkcje, jedna z nich co pewien czas sygnalizuje zajście pewnego zdarzenia - upływ czasu. Druga funkcja oczekuje notyfikacji od systemu regułowego i wyświetla informacje o przechwyconych zdarzeniach. Trzecia funkcja, jest pomocniczą funkcją wyświetlającą informacje o procesach uruchomionych w systemie. Następnie program definiuje prostą regułę i uruchamia wszystkie niezbędne procesy.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie wbudowanego systemu regułowego.}}
#+latex: \label{code:ex-forward-chaining}
#+begin_src scheme
(letrec ((monitor (lambda ()
                    (task-info)
                    (sleep 10000)
                    (monitor)))
         (timer (lambda (t)
                  (signal! `(curr-time ,t))
                  (sleep 1000)
                  (timer (+ t 1))))
         (listen (lambda ()
                   (let ((t (recv)))
                     (display "Current time: ")
                     (display (cdr (car t)))
                     (newline)
                     (listen)))))
  (spawn (lambda () (timer 0)))
  (notify-whenever (spawn (lambda ()
                            (listen)))
                   '(curr-time ?t))
  (monitor))
#+end_src
#+latex: \end{listing}

#+LaTeX: \pagebreak
** Obsługa złożonych zdarzeń
Program działa podobnie do przykładu z listingu [[ref:code:ex-forward-chaining]]. Definiowana jest złożona reguła, która notyfikuje proces nasłuchujący jedynie, gdy wartości powiązane z faktami =foo= oraz =bar= osiągają odpowiednie wartości.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Zastosowanie wbudowanego systemu regułowego do obsługi złożonych zdarzeń.}}
#+latex: \label{code:ex-complex-events}
#+begin_src scheme
(letrec ((monitor (lambda ()
                    (task-info)
                    (sleep 10000)
                    (monitor)))
         (notify (lambda (prefix t)
                   (assert! `(notify ,prefix ,(random)))
                   (sleep t)
                   (notify prefix t)))
         (listen (lambda ()
                   (let ((m (recv)))
                     (display "Complex event: ")
                     (display m)
                     (newline)
                     (listen)))))
  (notify-whenever (spawn listen)
                   '(filter (and (?notify foo ?foo)
                                 (?notify bar ?bar))
                            (>= ?foo 0.5)
                            (< ?foo 0.75)
                            (<= ?bar 0.1)))
  (spawn (lambda ()
           (notify 'foo 1000)))
  (spawn (lambda ()
           (notify 'bar 5000)))
  (monitor))
#+end_src
#+latex: \end{listing}

#+LaTeX: \pagebreak
** Wnioskowanie wstecz
Program prezentuje wykorzystanie wnioskowania wstecz wbudowanego w język systemu regułowego. Na bazie faktów wykonywany jest szereg operacji, a następnie program odpytuje bazę faktów o wartości, dla których wystąpiły fakty =foo= oraz =bar=. Wynikiem działania programu jest asocjacja =(?value . 2)=.

#+latex: \begin{listing}[H]
#+latex: \caption{\mylisting{Wykorzystanie wnioskowania wstecz.}}
#+latex: \label{code:ex-backward-chaining}
#+begin_src scheme
(assert! '(foo 1))
(assert! '(foo 2))
(assert! '(foo 3))
(assert! '(bar 2))
(assert! '(bar 3))
(retract! '(foo 2))
(signal! '(foo 4))

(select '(and (foo ?value)
              (bar ?value)))
#+end_src
#+latex: \end{listing}

* Spis wbudowanych funkcji i makr języka =FOOF=
#+LaTeX: \label{sec:built-ins}

#+LaTeX: \noindent
Lista wbudowanych funkcji i wartości dostępnych dla programisty (naturalnie istnieje możliwość powiększenia poniższej listy za pomocą wbudowanej funkcji =cpsfy=):
- =nil= - wartość reprezentująca pustą listę i jednocześnie logiczny fałsz.

- =(car x)= - funkcja zwraca pierwszy element pary =x=.

- =(cdr x)= - funkcja zwraca drugi element pary =x=.

- =(cadr x)= - funkcja zwraca drugi element listy =x= złożonej z par, odpowiada złożeniu funkcji =car= i =cdr=.

- =(cddr x)= - funkcja zwraca pozostałą cześć listy, po odrzuceniu dwóch pierwszych wartości.

- =(cons x y)= - funkcja tworzy parę dwóch wartości =x= oraz =y=.

- =(list args ...)= - funkcja tworzy listę złożoną z par, której elementami są przekazane argumenty.

- =(* args ...)= - funkcja oblicza iloczyn przekazanych wartości.

- =(+ args ...)= - funkcja oblicza sumę przekazanych wartości.

- =(- args ...)= - funkcja oblicza różnicę przekazanych wartości.

- =(= args ...)= - funkcja sprawdza matematyczną równość przekazanych wartości.

- =(< args ...)= - funkcja sprawdzająca, czy zadane wartości są posortowane rosnąco.

- =(sleep time)= - funkcja powoduje uśpienie aktualnie działającego mikroprocesu na zadany czas.

- =(self)= - funkcja zwraca identyfikator aktualnie działającego mikroprocesu.

- =(send pid msg)= - funkcja wysyła wiadomość =msg= do mikroprocesu o identyfikatorze =pid=.

- =(recv)= - funkcja przechwytuje wiadomość z kolejki wiadomości aktualnie funkcjonującego mikroprocesu i zwraca jej wartość.

- =(spawn function)= - funkcja odpowiedzialna za tworzenie nowych mikroprocesów, przyjmuje funkcję, która zostanie wywołana przez nowy mikroproces.

- =(assert! fact)= - funkcja pozwala na asercję faktów do wbudowanej bazy faktów.

- =(retract! fact)= - funkcja pozwala na retrakcję faktów z wbudowanej bazy faktów.

- =(signal! fact)= - funkcja pozwala na sygnalizację zajścia zdarzenia przez asercję i retrakcję faktu.

- =(select pattern)= - funkcja realizująca wnioskowanie wstecz, pozwala zadawać logiczne zapytania do wbudowanej w język bazy wiedzy.

- =(notify-whenever pid pattern)= - funkcja realizująca wnioskowanie w przód, pozwala definiować reguły, które notyfikują mikroproces o identyfikatorze =pid= w razie zaistnienia odpowiednich warunków.

- =(task-info)= - funkcja wyświetla statystyki z działania systemu, takie jak liczba, stan, czasy działania i priorytety mikroprocesów.

- =(display string)= - funkcja wyświetla przekazany ciąg znaków na ekranie komputera.

- =(newline)= - funkcja wyświetla znak nowej linii na ekranie komputera.

- =(random)= - funkcja zwraca pseudolosową wartość z przedziału (0, 1] o rozkładzie Gaussa.

#+LaTeX: \noindent
Lista wbudowanych makr dostępnych dla programisty:
- =(quasiquote ...)=, =(unquote ...)=, =(unquote-splicing ...)= - operacja quasiquote została zrealizowana jako szereg makr, dzięki czemu jej złożoność obliczeniowa podczas działania programu jest optymalna.

- =(define (name args ...) body ...)= - definicje funkcyjne są transformowane na definicje zmiennych, na przykład =(define (foo) 23)= jest transformowane do postaci =(define foo (lambda () 23))=, co ułatwia późniejsze przetwarzanie przez kompilator.

- =(when condition body ...)= - ułatwia tworzenie bloków warunkowych, odpowiada konstrukcji =(if condition (do body ...) nil)=.

- =(unless condition body ...)= - ułatwia tworzenie bloków warunkowych, odpowiada konstrukcji =(if condition nil (do body ...))=.

- =(cond ((condition body ...) ...))= - pozwala na łatwe tworzenie zagnieżdżonych bloków warunkowych.

- =(and x y)= - realizuje operację logicznego iloczynu dwóch wartości, odpowiada konstrukcji =(if x y false)=.

- =(or x y)= - realizuje operację logicznej sumy dwóch wartości, odpowiada konstrukcji =(if x true y)=.

- =(let ((var value) ...) body ...)= - pozwala na tworzenie lokalnych zmiennych, odpowiada wywołaniu funkcji anonimowej =((lambda (var ...) body ...) value ...)=.

- =(let* ((var value) ...) body ...)= - pozwala na tworzenie wzajemnie zależnych zmiennych, odpowiada zagnieżdżeniu kostrukcji =let=: =(let ((var value)) (let (...) ... body ...))=.

- =(structure definitions)= - pozwala na tworzenie struktur, stanowiących podstawowe bloki budulcowe programów w języku =FOOF=.

- =(module (name deps ...) body ...)= - umożliwia tworzenie parametryzowanych struktur, odpowiada konstrukcji =(define name (lambda (deps ...) (structure body ...)))=.

#+LaTeX: \noindent
Lista prymitywnych funkcji wykorzystywanych przez środowisko uruchomieniowe języka:
- =(&make-structure values ...)= - funkcja odpowiedzialna za tworzenio obiektów reprezentujących strukutry języka =FOOF=.

- =(&yield-cont cont value)= - funkcja odpowiada za tworzenie tak zwanych trampoliny, czyli par reifikowanych do postaci funkcyjnej kontynuacji =cont= oraz wartości =value=, które zostaną do nich przekazane.

- =(&uproc-error-handler)= - funkcja zwraca wartość aktualnie zadeklarowanej procedury obsługi błędu dla obecnie działającego mikroprocesu.

- =(&set-uproc-error-handler! function)= - funkcja pozwala zadeklarować nową procedurę obsługi sytuacji wyjątkowych dla obecnie działającego mikroprocesu.

- =(cpsfy function)= - funkcja pozwala transformować funkcje zdefiniowane w języku Scheme i udostępniać je w formacie odpowiednim do uruchomienia przez środowisko uruchomieniowe języka =FOOF=.

* Spisy rysunków i fragmentów kodu
#+latex: \label{sec:misc}

#+begin_latex
\begingroup
  \listoffigures
  \pagebreak
  \listofmylisting
\endgroup
#+end_latex
